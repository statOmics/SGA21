<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Koen Van den Berge" />


<title>Sequencing: Working with count data</title>

<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script src="site_libs/navigation-1.1/codefolding.js"></script>
<script src="site_libs/navigation-1.1/sourceembed.js"></script>
<script src="site_libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<link href="site_libs/pagedtable-1.1/css/pagedtable.css" rel="stylesheet" />
<script src="site_libs/pagedtable-1.1/js/pagedtable.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>


<style type="text/css">
  code {
    white-space: pre;
  }
  .sourceCode {
    overflow: visible;
  }
</style>
<style type="text/css" data-origin="pandoc">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  background-color: #f8f8f8; }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ef2929; } /* Alert */
code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #c4a000; } /* Attribute */
code span.bn { color: #0000cf; } /* BaseN */
code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4e9a06; } /* Char */
code span.cn { color: #000000; } /* Constant */
code span.co { color: #8f5902; font-style: italic; } /* Comment */
code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code span.dt { color: #204a87; } /* DataType */
code span.dv { color: #0000cf; } /* DecVal */
code span.er { color: #a40000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #0000cf; } /* Float */
code span.fu { color: #000000; } /* Function */
code span.im { } /* Import */
code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code span.ot { color: #8f5902; } /* Other */
code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code span.sc { color: #000000; } /* SpecialChar */
code span.ss { color: #4e9a06; } /* SpecialString */
code span.st { color: #4e9a06; } /* String */
code span.va { color: #000000; } /* Variable */
code span.vs { color: #4e9a06; } /* VerbatimString */
code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */

</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    for (var j = 0; j < rules.length; j++) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") continue;
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') continue;
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>


<style type="text/css">
#rmd-source-code {
  display: none;
}
</style>





<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.tab('show');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">SGA21</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">
    <span class="fa fa-home"></span>
     
  </a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-chalkboard-teacher"></span>
     
    Lectures
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="./docs/intro.pdf">1.1 Position</a>
    </li>
    <li>
      <a href="recapGeneralLinearModel.html">1.2 Recap linear model</a>
    </li>
    <li>
      <a href="./docs/martens_proteomics_bioinformatics.pdf">2.1 PDA - identification</a>
    </li>
    <li>
      <a href="pda_quantification_preprocessing.html">2.2 Quantification - Preprocessing</a>
    </li>
    <li>
      <a href="pda_robustSummarisation_peptideModels.html">2.2 Wrap-up Preprocessing - Peptide-Level-Models</a>
    </li>
    <li>
      <a href="pda_quantification_inference.html">2.3 Quantification - Differential Abundance Analysis</a>
    </li>
    <li>
      <a href="pda_blocking_wrapup.html">2.3 Wrap-up DA - Blocking</a>
    </li>
    <li>
      <a href="technicalDetailsProteomics.html">2.4. DA Technical Details</a>
    </li>
    <li>
      <a href="./docs/stagewiseTesting.pdf">2.5 Stage-wise testing</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-laptop"></span>
     
    tutorials
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="multipleRegression_KPNA2.html">1 Intro KPNA2</a>
    </li>
    <li>
      <a href="https://www.compomics.com/bioinformatics-for-proteomics/">2.1 Identification</a>
    </li>
    <li>
      <a href="pda_tutorialPreprocessing.html">2.2 DA - Preprocessing</a>
    </li>
    <li>
      <a href="pda_tutorialDesign.html">2.3 DA - Design</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">

<div class="btn-group pull-right float-right">
<button type="button" class="btn btn-default btn-xs btn-secondary btn-sm dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu dropdown-menu-right" style="min-width: 50px;">
<li><a id="rmd-download-source" href="#">Download Rmd</a></li>
</ul>
</div>



<h1 class="title toc-ignore">Sequencing: Working with count data</h1>
<h4 class="author">Koen Van den Berge</h4>
<h4 class="date">Last edited on 28 October, 2021</h4>

</div>


<p>In this lecture we will introduce the main principles of working with count data, and how to model these using generalized linear models (GLMs). We focus on introducing the concept of generalized linear models, and how to interpret its results. We touch briefly upon statistical inference, providing the main results rather than the theory behind it, such that they can be applied to genomics data analysis.</p>
<div id="the-poisson-distribution" class="section level1">
<h1><span class="header-section-number">1</span> The Poisson distribution</h1>
<ul>
<li>The Poisson distribution is a typical count distribution that is generally popular and fairly easy to work with. It is defined by a single parameter: its mean <span class="math inline">\(\mu\)</span>. For a Poisson distributed random variable <span class="math inline">\(Y_i\)</span> with observations <span class="math inline">\(i \in \{1, \ldots, n\}\)</span>, its variance is equal to its mean. That is, if <span class="math inline">\(Y_i \sim Poi(\mu)\)</span>, then <span class="math inline">\(E(Y_i) = Var(Y_i) = \mu\)</span>.</li>
<li>This immediately shows an important feature of count data: the <strong>mean-variance relationship</strong>. Indeed, in count data, the variance will always be a function of the mean.</li>
<li>This is quite intuitive. Consider the following example. You have two bird cages, where in one bird cage there are <span class="math inline">\(10\)</span> birds, while in the other there are <span class="math inline">\(100\)</span> birds. You let a sample of people count the number of birds in either one of the cages. It seems unlikely that a person in front of the 10-bird cage would come up with an estimate of <span class="math inline">\(5\)</span>, while it seems quite likely that someone in front of the 100-bird cage would come up with an estimate of <span class="math inline">\(95\)</span>. Even though the difference from the true value is the same, the exact value has an impact on the plausible deviation around it.</li>
</ul>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1"></a><span class="kw">set.seed</span>(<span class="dv">11</span>)</span>
<span id="cb1-2"><a href="#cb1-2"></a>y1 &lt;-<span class="st"> </span><span class="kw">rpois</span>(<span class="dt">n=</span><span class="dv">500</span>, <span class="dt">lambda=</span><span class="dv">10</span>)</span>
<span id="cb1-3"><a href="#cb1-3"></a>y2 &lt;-<span class="st"> </span><span class="kw">rpois</span>(<span class="dt">n=</span><span class="dv">500</span>, <span class="dt">lambda=</span><span class="dv">100</span>)</span>
<span id="cb1-4"><a href="#cb1-4"></a></span>
<span id="cb1-5"><a href="#cb1-5"></a><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb1-6"><a href="#cb1-6"></a><span class="kw">hist</span>(y1, <span class="dt">main=</span><span class="st">&quot;Poisson(10)&quot;</span>, <span class="dt">breaks=</span><span class="dv">40</span>)</span>
<span id="cb1-7"><a href="#cb1-7"></a><span class="kw">hist</span>(y2, <span class="dt">main=</span><span class="st">&quot;Poisson(100)&quot;</span>, <span class="dt">breaks=</span><span class="dv">40</span>)</span></code></pre></div>
<p><img src="sequencing_countData_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
<div id="the-poisson-distribution-in-rna-seq" class="section level2">
<h2><span class="header-section-number">1.1</span> The Poisson distribution in RNA-seq</h2>
<ul>
<li>In RNA-seq, technical replicates represent different aliquots of the same sample being sequenced repeatedly. The underlying true expression of a gene can hence safely be assumed to be equal across these technical replicates.</li>
<li><a href="https://genome.cshlp.org/content/18/9/1509">Marioni <em>et al.</em> (2008)</a> have shown that, for most genes, the distribution of observed gene expression counts across technical replicates follow a Poisson distribution. A small proportion of genes (<span class="math inline">\(\sim 0.5\%\)</span>) do not follow this Poisson model, however, and actually show evidence for <em>‘extra-Poisson variation’</em>.</li>
</ul>
<div class="figure">
<img src="images_sequencing/marioniFigs_cropped.png" alt="Figure: Technical replication in RNA-seq. Figures from Marioni et al. (2008)." width="1996" />
<p class="caption">
Figure: Technical replication in RNA-seq. Figures from Marioni et al. (2008).
</p>
</div>
</div>
<div id="relative-uncertainty-for-poisson-distributed-random-variables" class="section level2">
<h2><span class="header-section-number">1.2</span> Relative uncertainty for Poisson distributed random variables</h2>
<p>Take a minute to consider the following question:</p>
<ul>
<li>Suppose that we have a solid tumor sample from a cancer patient, as well as a sample of surrounding healthy tissue. For each sample, we have three technical replicates at our disposal. Let <span class="math inline">\(Y_{grt}\)</span> denote the observed gene expression values of gene <span class="math inline">\(g\)</span> in replicate <span class="math inline">\(r \in \{1,2,3\}\)</span> from tissue <span class="math inline">\(t \in \{0,1\}\)</span>, where <span class="math inline">\(t=0\)</span> denotes healthy tissue and <span class="math inline">\(t=1\)</span> denotes tumoral tissue.</li>
<li>We then know that the random variables <span class="math inline">\(Y_{gr0}\)</span> and <span class="math inline">\(Y_{gr1}\)</span> follow a Poisson distribution, and we would estimate its mean as <span class="math inline">\(\bar{Y}_{g0} = \frac{1}{3} \sum_{r=1}^3 Y_{gr0}\)</span> and <span class="math inline">\(\bar{Y}_{g1} = \frac{1}{3} \sum_{r=1}^3 Y_{gr1}\)</span>, respectively.</li>
<li>Similar, for another gene <span class="math inline">\(k\)</span>, we observe <span class="math inline">\(Y_{krt}\)</span>, and estimate <span class="math inline">\(\bar{Y}_{k0}\)</span> and <span class="math inline">\(\bar{Y}_{k1}\)</span> correspondingly.</li>
<li>Now suppose that <span class="math inline">\(\beta_{k} = \bar{Y}_{k1} / \bar{Y}_{k0} = 5\)</span>, but also <span class="math inline">\(\beta_g = \bar{Y}_{g1} / \bar{Y}_{g0} = 5\)</span>, i.e., the two genes have the same average expression ratio (also often called a fold-change) across samples. However, they are differently expressed as <span class="math inline">\(\bar{Y}_{k1} = 100\)</span>, and <span class="math inline">\(\bar{Y}_{g1} = 10\)</span> (making <span class="math inline">\(\bar{Y}_{k0} = 20\)</span>, and <span class="math inline">\(\bar{Y}_{g0} = 2\)</span>).</li>
<li>For which of the two genes is the uncertainty on the expression ratio the highest? In other words, do we trust <span class="math inline">\(\beta_k\)</span> more or do we trust <span class="math inline">\(\beta_g\)</span> more?</li>
</ul>
<hr />
<p>Let’s approximate the uncertainty in <span class="math inline">\(beta_g\)</span> and <span class="math inline">\(\beta_k\)</span> using simulation:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1"></a>N &lt;-<span class="st"> </span><span class="fl">1e3</span></span>
<span id="cb2-2"><a href="#cb2-2"></a>beta_g &lt;-<span class="st"> </span>beta_k &lt;-<span class="st"> </span><span class="kw">vector</span>(<span class="dt">length=</span>N)</span>
<span id="cb2-3"><a href="#cb2-3"></a><span class="cf">for</span>(ii <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>N){</span>
<span id="cb2-4"><a href="#cb2-4"></a>  ygr1 &lt;-<span class="st"> </span><span class="kw">rpois</span>(<span class="dt">n=</span><span class="dv">3</span>, <span class="dt">lambda=</span><span class="dv">10</span>)</span>
<span id="cb2-5"><a href="#cb2-5"></a>  ygr0 &lt;-<span class="st"> </span><span class="kw">rpois</span>(<span class="dt">n=</span><span class="dv">3</span>, <span class="dt">lambda=</span><span class="dv">2</span>)</span>
<span id="cb2-6"><a href="#cb2-6"></a>  ykr1 &lt;-<span class="st"> </span><span class="kw">rpois</span>(<span class="dt">n=</span><span class="dv">3</span>, <span class="dt">lambda=</span><span class="dv">100</span>)</span>
<span id="cb2-7"><a href="#cb2-7"></a>  ykr0 &lt;-<span class="st"> </span><span class="kw">rpois</span>(<span class="dt">n=</span><span class="dv">3</span>, <span class="dt">lambda=</span><span class="dv">20</span>)</span>
<span id="cb2-8"><a href="#cb2-8"></a>  beta_g[ii] &lt;-<span class="st"> </span><span class="kw">mean</span>(ygr1) <span class="op">/</span><span class="st"> </span><span class="kw">mean</span>(ygr0)</span>
<span id="cb2-9"><a href="#cb2-9"></a>  beta_k[ii] &lt;-<span class="st"> </span><span class="kw">mean</span>(ykr1) <span class="op">/</span><span class="st"> </span><span class="kw">mean</span>(ykr0)</span>
<span id="cb2-10"><a href="#cb2-10"></a>}</span>
<span id="cb2-11"><a href="#cb2-11"></a></span>
<span id="cb2-12"><a href="#cb2-12"></a><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>), <span class="dt">mar=</span><span class="kw">c</span>(<span class="dv">4</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">1</span>))</span>
<span id="cb2-13"><a href="#cb2-13"></a><span class="kw">hist</span>(beta_g, <span class="dt">breaks=</span><span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">50</span>,<span class="dt">by=</span><span class="dv">1</span>), <span class="dt">xlim=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">50</span>))</span>
<span id="cb2-14"><a href="#cb2-14"></a><span class="kw">hist</span>(beta_k, <span class="dt">breaks=</span><span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">50</span>,<span class="dt">by=</span><span class="dv">1</span>), <span class="dt">xlim=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">50</span>))</span></code></pre></div>
<p><img src="sequencing_countData_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<hr />
<p>We clearly see that the uncertainty on <span class="math inline">\(\beta_k\)</span> is much lower than on <span class="math inline">\(\beta_g\)</span>. Even though the variance on the counts of gene <span class="math inline">\(k\)</span> is higher, since its mean is higher and it is distributed as a Poisson variable. How do we explain this?</p>
<ul>
<li>We may explain this by considering the relative uncertainty on the mean. Relative uncertainty may be defined as the coefficient of variation <span class="math inline">\(CV = \frac{\sigma}{\mu}\)</span> (this is, the standard deviation divided by the mean). Indeed, the CV describes the relative deviation of the distribution relative to its mean, where a low CV indicates low dispersion with respect to the mean.</li>
<li>Calculating the CV shows that <strong>the relative uncertainty for gene <span class="math inline">\(k\)</span> than for gene <span class="math inline">\(g\)</span>, even though the variance on the raw counts is higher for gene <span class="math inline">\(k\)</span> than for gene <span class="math inline">\(g\)</span></strong>.</li>
<li>This lower relative uncertainty on the mean then propagates further to a lower uncertainty on the fold-change. This basic result will be essential for understanding the results of a differential expression analysis!</li>
</ul>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1"></a><span class="kw">sqrt</span>(<span class="dv">100</span>)<span class="op">/</span><span class="dv">100</span> <span class="co">#CV for gene k</span></span></code></pre></div>
<pre><code>## [1] 0.1</code></pre>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1"></a><span class="kw">sqrt</span>(<span class="dv">10</span>)<span class="op">/</span><span class="dv">10</span> <span class="co">#CV for gene g</span></span></code></pre></div>
<pre><code>## [1] 0.3162278</code></pre>
</div>
</div>
<div id="modeling-count-data-generalized-linear-models" class="section level1">
<h1><span class="header-section-number">2</span> Modeling count data: Generalized linear models</h1>
<p>Just like we have modeled protein abundances in the proteomics module of this course in order to assess differential protein abundance, we can model gene expression counts to identify genes with differences in average expression between groups of samples.</p>
<div id="why-we-cant-use-linear-models-to-model-count-data" class="section level2">
<h2><span class="header-section-number">2.1</span> Why we can(’t) use linear models to model count data</h2>
<ul>
<li>If we’re using a linear model to model a response <span class="math inline">\(Y_i\)</span>, with <span class="math inline">\(i \in \{1, \ldots, n\}\)</span> in function of a single covariate <span class="math inline">\(X_i\)</span>, the linear model can be defined as follows:</li>
</ul>
<p><span class="math display">\[
\left\{
\begin{array}{ccc}
Y_i &amp; = &amp; \beta_0 + \beta_1 X_i + \epsilon_i \\
Y_i | X_i &amp; \sim &amp; N(\beta_0 + \beta_1 X_i, \sigma^2 \mathbf{I}).
\end{array}
\right.
\]</span></p>
<ul>
<li>Or, equivalently, we’ve seen we can write it in matrix form as <span class="math display">\[
  \left\{
  \begin{array}{ccc}
  Y_i &amp; = &amp; \mathbf{X}^T_i \beta + \epsilon_i \\
  Y_i | \mathbf{X}_i &amp; \sim &amp; N(\mathbf{X}^T_i \beta, \sigma^2 \mathbf{I}),
  \end{array}
  \right.
  \]</span> where <span class="math inline">\(\mathbf{X}\)</span> now represents our <span class="math inline">\(n \times p\)</span> design matrix, with row <span class="math inline">\(i\)</span> corresponding to observation <span class="math inline">\(i\)</span>.</li>
</ul>
<hr />
<ul>
<li>The variance-covariance matrix of <span class="math inline">\(\mathbf{Y}\)</span> is assumed a diagonal matrix with <span class="math inline">\(\sigma^2\)</span> on the diagonal elements and zero everywhere else. This means that the data points are uncorrelated, and that every observation has the same variance <span class="math inline">\(\sigma^2\)</span>, also referred to as homoscedasticity.</li>
<li>The latter doesn’t hold for count data, due to the mean-variance relationship. This makes linear models, in its basic form, unsuitable to model count data.</li>
<li>In addition, count data are non-negative, while there are no such constraints in the standard linear model to make sure that our estimates will be non-negative. Indeed, <span class="math inline">\(\hat{Y}_i = \mathbf{X}^T_i \hat{\beta} \in ] -\infty, \infty[\)</span>.</li>
</ul>
</div>
<div id="generalized-linear-models" class="section level2">
<h2><span class="header-section-number">2.2</span> Generalized linear models</h2>
<ul>
<li>As the name suggests, generalized linear models (GLMs) extend linear models. In GLMs, we extend two things with respect to the linear model:
<ul>
<li>The <strong>conditional distribution of the response variable <span class="math inline">\(Y_i | X_i\)</span></strong> can be assumed to follow any distribution that belongs to the <strong>exponential family</strong> of distributions, which includes the Gaussian but also other commonly known distributions, such as the Binomial, Gamma and Poisson distribution.</li>
<li>The linear model assumed a linear relationship between <span class="math inline">\(Y_i\)</span> and <span class="math inline">\(X_i\)</span>, since we assumed that <span class="math inline">\(E(Y_i | X_i) = \mathbf{X}^T_i \beta\)</span>. In GLMs, we will allow a <strong>link function</strong> <span class="math inline">\(g()\)</span> that links the conditional mean to the covariates. Hence, in GLMs we have that <span class="math inline">\(g(E(Y_i | X_i)) = \mathbf{X}^T_i \beta\)</span>. Note that each family has got a canonical link function, which is the identity link function <span class="math inline">\(g(\mu) = \mu\)</span> for Gaussian, the log link function <span class="math inline">\(g(\mu) = \log \mu\)</span> for Poisson, or the logit link function <span class="math inline">\(g(\mu) = \log(\frac{\mu}{1-\mu})\)</span> for Binomial.</li>
</ul></li>
</ul>
<div id="a-poisson-glm" class="section level3">
<h3><span class="header-section-number">2.2.1</span> A Poisson GLM</h3>
<ul>
<li>We can define a Poisson GLM as follows <span class="math display">\[
  \left\{
  \begin{array}{ccc}
  Y_i &amp; \sim &amp; Poi(\mu_i) \\
  \log \mu_i &amp; = &amp; \eta_i \\
  \eta_i &amp; = &amp; \mathbf{X}^T_i \beta \\
  \end{array}
  \right.
  \]</span> where <span class="math inline">\(Y_i\)</span> is the response variable, with mean <span class="math inline">\(\mu_i\)</span>, <span class="math inline">\(\eta_i\)</span> is the linear predictor, <span class="math inline">\(\mathbf{X}\)</span> is the <span class="math inline">\(n \times p\)</span> model matrix and <span class="math inline">\(\beta\)</span> is the <span class="math inline">\(p \times 1\)</span> matrix of regression coefficients.</li>
<li>It is insightful to compare this model to a linear model where <span class="math inline">\(Y_i\)</span> is log-transformed. Indeed, in the linear model case, we would be modeling <span class="math inline">\(E(\log Y_i )\)</span>, while in the GLM we are modeling <span class="math inline">\(\log E(Y_i)\)</span>.</li>
<li>This shows that in the GLM setting we are modeling a transformed version of the expected value, and after retransforming we can interpret the fit in terms of the mean of our response variable. In the transformed linear model, however, we are working with the expected value of a transformed version of our response variable, and we will not be able to interpret the fit in terms of the mean (because <span class="math inline">\(E( \log Y_i) \ne \log E(Y_i)\)</span>. In this specific case, we would have to resort to interpreting changes in terms of a geometric mean.</li>
<li>Also note that <span class="math inline">\(\mathbf{X}^T_i \beta \in ]-\infty, \infty[\)</span>, while <span class="math inline">\(Y_i\)</span> must be non-negative <span class="math inline">\([0, \infty[\)</span>. The link function helps with this, since the exponential function transforms any real number to a non-negative number, i.e., <span class="math inline">\(\exp(\mathbf{X}^T_i \beta) \in [0, \infty[\)</span>.</li>
</ul>
</div>
<div id="parameter-estimation-using-maximum-likelihood" class="section level3">
<h3><span class="header-section-number">2.2.2</span> Parameter estimation using maximum likelihood</h3>
<ul>
<li>In maximum likelihood, we attempt to <strong>maximize the likelihood function of the data</strong>, under the posited assumptions. The likelihood function is typically parametrized by a limited number of parameters, hence we can find the values of the parameters that maximize the likelihood function.</li>
<li>We do this by finding the point on the likelihood function where its first derivative equals zero, as this must be a maximum of the function. For non-convex likelihood functions, this may be a local maximum, but for GLMs the likelihood function is convex and therefore the obtained maximum must be the global maximum.</li>
</ul>
<div id="maximum-likelihood-for-a-linear-model" class="section level4">
<h4><span class="header-section-number">2.2.2.1</span> Maximum likelihood for a linear model</h4>
<p>For linear models, we can derive an equivalent estimator for <span class="math inline">\(\beta\)</span> using maximum likelihood estimation as we had derived in our recap lecture using least squares estimation. We can define a linear model as</p>
<p><span class="math display">\[
Y_i \sim N(\mu_i, \sigma^2\mathbf{I}) \\
\mu_i = \mathbf{X}_i \mathbf{\beta}
\]</span></p>
<p>The likelihood function of the data is the product of the likelihoods of each datum. Since we are assuming a Gaussian distribution, we use the Gaussian probability density function:</p>
<p><span class="math display">\[
L(\mathbf{Y}; \beta, \sigma) = \prod_{i=1}^n \frac{1}{\sqrt{2 \pi \sigma^2}} \exp \left\{ - \frac{(Y_i - \mathbf{X}_i \beta)^2}{2 \sigma^2} \right\}
\]</span></p>
<p>Log-likelihood function</p>
<p><span class="math display">\[
\ell(\mathbf{Y}; \beta, \sigma) = \sum_{i=1}^n \left\{ -\frac{1}{2} \log(2\pi \sigma^2) - \frac{1}{2\sigma^2} (Y_i - \mathbf{X}_i \beta)^2 \right\}
\]</span></p>
<p>Score function is the derivative of the log-likelihood</p>
<p><span class="math display">\[
S(\mathbf{\beta}) = \frac{\partial \ell(\mathbf{Y}; \beta, \sigma)}{\partial \beta} = \sum_{i=1}^n \frac{1}{\sigma^2} \mathbf{X}_i (Y_i - \mathbf{X}_i \beta)
\]</span></p>
<p>Set to zero and solve</p>
<p><span class="math display">\[
\mathbf{X}^T\mathbf{Y} - \mathbf{X}^T \mathbf{X} \mathbf{\beta} = \mathbf{0} \\
\rightarrow \widehat{\mathbf{\beta}} = (\mathbf{X}^T \mathbf{X})^{-1} \mathbf{X}^T\mathbf{Y}
\]</span></p>
<p>which gives us exactly the same estimator as we had derived using least squares!</p>
</div>
<div id="maximum-likelihood-for-a-generalized-linear-model" class="section level4">
<h4><span class="header-section-number">2.2.2.2</span> Maximum likelihood for a generalized linear model</h4>
<p>Now that we know how to use maximum likelihood for parameter estimation, we can also apply it to estimate the parameters of a generalized linear model. Let’s try it for the Poisson GLM we have just introduced:</p>
<p><span class="math display">\[
\left\{
\begin{array}{ccc}
Y_i &amp; \sim &amp; Poi(\mu_i) \\
\log \mu_i &amp; = &amp; \eta_i \\
\eta_i &amp; = &amp; \mathbf{X}^T_i \beta \\
\end{array}
\right.
\]</span></p>
<p>Likelihood function of the Poisson distribution</p>
<p><span class="math display">\[
L(Y_i ; \mu) = \prod_{i=1}^n \frac{e^{-\mu} \mu^{Y_i}}{Y_i!}
\]</span></p>
<p>Log-likelihood function</p>
<p><span class="math display">\[
\ell(Y_i ; \mu) = \sum_{i=1}^n - \mu + Y_i \log(\mu) - \log (Y_i!)
\]</span></p>
<p>Note that the score function is the derivative of the log-likelihood with respect to our parameter of interest, <span class="math inline">\(\beta\)</span>. So let’s first rewrite our log-likelihood as a function of our parameter of interest. We know from the model that <span class="math inline">\(\mu_i = \exp(\mathbf{X}_i \mathbf{\beta})\)</span>.</p>
<p><span class="math display">\[
\ell(Y_i ; \beta) = \sum_{i=1}^n - \exp(\mathbf{X}_i \mathbf{\beta}) + Y_i (\mathbf{X}_i \mathbf{\beta}) - \log (Y_i!)
\]</span></p>
<p>The score function then equals</p>
<p><span class="math display">\[
S(\mathbf{\beta}) = \frac{\partial \ell(\mathbf{Y}; \beta)}{\partial \beta} = \sum_{i=1}^n -\mathbf{X}_i^T \exp(\mathbf{X}_i \mathbf{\beta}) + \mathbf{X}_i^TY_i = -\mathbf{X}^T \exp(\mathbf{X} \mathbf{\beta}) + \mathbf{X}^T \mathbf{Y}
\]</span></p>
<p>Set to zero and solve</p>
<p><span class="math display">\[
\mathbf{X}^T \mathbf{Y} = \mathbf{X}^T \exp(\mathbf{X} \mathbf{\beta})
\]</span></p>
<p>However, since this is a non-linear equation in <span class="math inline">\(\beta\)</span>, we cannot find a closed-form solution! You may see this more clearly when writing out in non-matrix form</p>
<p><span class="math display">\[
\sum_i \sum_p x_{ip} \exp(x_{ip} \beta_p) = \sum_i \sum_p x_{ip} Y_i.
\]</span></p>
<hr />
<ul>
<li>The above derivations show that estimating the parameters of a GLM is much harder as compared to a linear model.</li>
<li>The <strong>iterative reweighted least squares (IRLS)</strong> algorithm is usually adopted for fitting GLMs using maximum likelihood. As the name suggests, it is an iterative algorithm, where each data point is reweighted in each iteration according to the assumed mean-variance relationship, which is a function of its estimated mean of the previous iteration. Indeed, observations with high variance will be downweighted and vice versa. IRLS uses the derivative of the score function (i.e., the second derivative of the log-likelihood function) to move into the direction where the first derivative is zero.</li>
</ul>
<p><img src="images_sequencing/irlsScheme.png" width="983" /> Figure: Finding the root of the score function using Newton-Raphson optimization. The Figure shows estimation of a single <span class="math inline">\(\beta\)</span> parameter. The black solid line is the Score function evaluated at <span class="math inline">\(\beta\)</span>. An initial estimate of <span class="math inline">\(\beta\)</span> is 2.25, which is represented by the dotted line. The value of the score function of this initial value is <span class="math inline">\(S(\beta^k)\)</span>. The first derivative of the score function at that point, evaluated at <span class="math inline">\(\beta = 2.25\)</span>, is represented by the solid blue line and is given by <span class="math inline">\(\frac{\partial S(\beta)}{\partial \beta}\)</span>. The value of <span class="math inline">\(\beta\)</span> where the solid blue line crosses zero is the new estimate for <span class="math inline">\(\beta\)</span>, namely <span class="math inline">\(\beta^{k+1}\)</span> which has a value of 1.4. The difference between <span class="math inline">\(\beta^{k+1}\)</span> and <span class="math inline">\(\beta^{k}\)</span> is given by <span class="math inline">\(\left \{ \frac{ \partial S(\beta)}{ \partial \beta} \right \}^{-1} S(\beta^k)\)</span>. This procedure is iterated until a convergence in the <span class="math inline">\(\beta\)</span> estimate is met.</p>
</div>
</div>
<div id="generalized-linear-models-in-r" class="section level3">
<h3><span class="header-section-number">2.2.3</span> Generalized linear models in <code>R</code></h3>
<ul>
<li><p>In order to get familiar with GLMs, we will fit a Poisson GLM in <code>R</code>, using the <code>Bikeshare</code> dataset as part of the <code>ISLR2</code> package. This dataset records how many bikes were being used from a bike-sharing service, every hour of the day over a full year (365 days).</p></li>
<li><p>Full information of the dataset is provided <a href="https://archive.ics.uci.edu/ml/datasets/bike+sharing+dataset">here</a>. Variables of interest for us are:</p>
<ul>
<li><p><code>bikers</code>: Discrete count variable; the number of bikes being used that hour.</p></li>
<li><p><code>hum</code>: Continuous variable ranging between 0 and 1; normalized humidity.</p></li>
<li><p><code>hr</code>: Categorical variable between 0 and 23; the hour of the day. One could also consider this variable to be numeric and model it as such, but the data exploration will show that’s not appropriate.</p></li>
<li><p><code>weathersit</code>: Categorical variable; the weather condition of that hour, with</p>
<ol style="list-style-type: decimal">
<li>Clear, Few clouds, Partly cloudy.</li>
<li>Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist.</li>
<li>Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds.</li>
<li>Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog.</li>
</ol></li>
</ul></li>
</ul>
<hr />
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1"></a><span class="co"># if ISLR2 isn&#39;t installed, install it:</span></span>
<span id="cb7-2"><a href="#cb7-2"></a><span class="cf">if</span>(<span class="op">!</span><span class="st">&quot;ISLR2&quot;</span> <span class="op">%in%</span><span class="st"> </span><span class="kw">installed.packages</span>()[,<span class="dv">1</span>]){</span>
<span id="cb7-3"><a href="#cb7-3"></a>  <span class="kw">install.packages</span>(<span class="st">&quot;ISLR2&quot;</span>)</span>
<span id="cb7-4"><a href="#cb7-4"></a>}</span></code></pre></div>
<pre><code>## Installing package into &#39;/Users/runner/work/_temp/Library&#39;
## (as &#39;lib&#39; is unspecified)</code></pre>
<pre><code>## 
## The downloaded binary packages are in
##  /var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T//RtmpX6spfo/downloaded_packages</code></pre>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1"></a><span class="co"># load and preview the dataset:</span></span>
<span id="cb10-2"><a href="#cb10-2"></a><span class="kw">data</span>(<span class="st">&quot;Bikeshare&quot;</span>, <span class="dt">package=</span><span class="st">&quot;ISLR2&quot;</span>)</span>
<span id="cb10-3"><a href="#cb10-3"></a><span class="kw">head</span>(Bikeshare)</span></code></pre></div>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":[""],"name":["_rn_"],"type":[""],"align":["left"]},{"label":["season"],"name":[1],"type":["dbl"],"align":["right"]},{"label":["mnth"],"name":[2],"type":["fct"],"align":["left"]},{"label":["day"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["hr"],"name":[4],"type":["fct"],"align":["left"]},{"label":["holiday"],"name":[5],"type":["dbl"],"align":["right"]},{"label":["weekday"],"name":[6],"type":["dbl"],"align":["right"]},{"label":["workingday"],"name":[7],"type":["dbl"],"align":["right"]},{"label":["weathersit"],"name":[8],"type":["fct"],"align":["left"]},{"label":["temp"],"name":[9],"type":["dbl"],"align":["right"]},{"label":["atemp"],"name":[10],"type":["dbl"],"align":["right"]},{"label":["hum"],"name":[11],"type":["dbl"],"align":["right"]},{"label":["windspeed"],"name":[12],"type":["dbl"],"align":["right"]},{"label":["casual"],"name":[13],"type":["dbl"],"align":["right"]},{"label":["registered"],"name":[14],"type":["dbl"],"align":["right"]},{"label":["bikers"],"name":[15],"type":["dbl"],"align":["right"]}],"data":[{"1":"1","2":"Jan","3":"1","4":"0","5":"0","6":"6","7":"0","8":"clear","9":"0.24","10":"0.2879","11":"0.81","12":"0.0000","13":"3","14":"13","15":"16","_rn_":"1"},{"1":"1","2":"Jan","3":"1","4":"1","5":"0","6":"6","7":"0","8":"clear","9":"0.22","10":"0.2727","11":"0.80","12":"0.0000","13":"8","14":"32","15":"40","_rn_":"2"},{"1":"1","2":"Jan","3":"1","4":"2","5":"0","6":"6","7":"0","8":"clear","9":"0.22","10":"0.2727","11":"0.80","12":"0.0000","13":"5","14":"27","15":"32","_rn_":"3"},{"1":"1","2":"Jan","3":"1","4":"3","5":"0","6":"6","7":"0","8":"clear","9":"0.24","10":"0.2879","11":"0.75","12":"0.0000","13":"3","14":"10","15":"13","_rn_":"4"},{"1":"1","2":"Jan","3":"1","4":"4","5":"0","6":"6","7":"0","8":"clear","9":"0.24","10":"0.2879","11":"0.75","12":"0.0000","13":"0","14":"1","15":"1","_rn_":"5"},{"1":"1","2":"Jan","3":"1","4":"5","5":"0","6":"6","7":"0","8":"cloudy/misty","9":"0.24","10":"0.2576","11":"0.75","12":"0.0896","13":"0","14":"1","15":"1","_rn_":"6"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1"></a><span class="co"># association with weather on count and log scale</span></span>
<span id="cb11-2"><a href="#cb11-2"></a><span class="kw">barplot</span>(<span class="kw">table</span>(Bikeshare<span class="op">$</span>weathersit))</span></code></pre></div>
<p><img src="sequencing_countData_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1"></a><span class="kw">boxplot</span>(bikers <span class="op">~</span><span class="st"> </span>weathersit, <span class="dt">data=</span>Bikeshare,</span>
<span id="cb12-2"><a href="#cb12-2"></a>        <span class="dt">xlab =</span> <span class="st">&quot;Weather&quot;</span>, <span class="dt">ylab =</span> <span class="st">&quot;Bikers&quot;</span>)</span></code></pre></div>
<p><img src="sequencing_countData_files/figure-html/unnamed-chunk-6-2.png" width="672" /></p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1"></a><span class="kw">boxplot</span>(<span class="kw">log1p</span>(bikers) <span class="op">~</span><span class="st"> </span>weathersit, <span class="dt">data=</span>Bikeshare,</span>
<span id="cb13-2"><a href="#cb13-2"></a>        <span class="dt">xlab =</span> <span class="st">&quot;Weather&quot;</span>, <span class="dt">ylab =</span> <span class="st">&quot;Log (bikers +1)&quot;</span>)</span></code></pre></div>
<p><img src="sequencing_countData_files/figure-html/unnamed-chunk-6-3.png" width="672" /></p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1"></a><span class="co"># association with humidity on count and log scale</span></span>
<span id="cb14-2"><a href="#cb14-2"></a><span class="kw">hist</span>(Bikeshare<span class="op">$</span>hum, <span class="dt">breaks=</span><span class="dv">40</span>)</span></code></pre></div>
<p><img src="sequencing_countData_files/figure-html/unnamed-chunk-6-4.png" width="672" /></p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1"></a><span class="kw">plot</span>(bikers <span class="op">~</span><span class="st"> </span>hum, <span class="dt">data=</span>Bikeshare, <span class="dt">pch=</span><span class="dv">16</span>, <span class="dt">cex=</span><span class="dv">1</span><span class="op">/</span><span class="dv">2</span>,</span>
<span id="cb15-2"><a href="#cb15-2"></a>        <span class="dt">xlab =</span> <span class="st">&quot;Humidity&quot;</span>, <span class="dt">ylab =</span> <span class="st">&quot;Bikers&quot;</span>)</span>
<span id="cb15-3"><a href="#cb15-3"></a>loHum &lt;-<span class="st"> </span><span class="kw">loess</span>(bikers <span class="op">~</span><span class="st"> </span>hum, <span class="dt">data=</span>Bikeshare)</span>
<span id="cb15-4"><a href="#cb15-4"></a>xGrid &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dt">length=</span><span class="dv">50</span>)</span>
<span id="cb15-5"><a href="#cb15-5"></a>yhat &lt;-<span class="st"> </span><span class="kw">predict</span>(loHum, <span class="kw">data.frame</span>(<span class="dt">hum =</span> xGrid))</span>
<span id="cb15-6"><a href="#cb15-6"></a><span class="kw">lines</span>(<span class="dt">x=</span>xGrid, <span class="dt">y=</span>yhat, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">lwd=</span><span class="dv">3</span>)</span></code></pre></div>
<p><img src="sequencing_countData_files/figure-html/unnamed-chunk-6-5.png" width="672" /></p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1"></a><span class="kw">plot</span>(<span class="kw">log1p</span>(bikers) <span class="op">~</span><span class="st"> </span>hum, <span class="dt">data=</span>Bikeshare, <span class="dt">pch=</span><span class="dv">16</span>, <span class="dt">cex=</span><span class="dv">1</span><span class="op">/</span><span class="dv">2</span>,</span>
<span id="cb16-2"><a href="#cb16-2"></a>        <span class="dt">xlab =</span> <span class="st">&quot;Humidity&quot;</span>, <span class="dt">ylab =</span> <span class="st">&quot;Log (bikers +1)&quot;</span>)</span>
<span id="cb16-3"><a href="#cb16-3"></a>loHum &lt;-<span class="st"> </span><span class="kw">loess</span>(<span class="kw">log1p</span>(bikers) <span class="op">~</span><span class="st"> </span>hum, <span class="dt">data=</span>Bikeshare)</span>
<span id="cb16-4"><a href="#cb16-4"></a>xGrid &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dt">length=</span><span class="dv">50</span>)</span>
<span id="cb16-5"><a href="#cb16-5"></a>yhat &lt;-<span class="st"> </span><span class="kw">predict</span>(loHum, <span class="kw">data.frame</span>(<span class="dt">hum =</span> xGrid))</span>
<span id="cb16-6"><a href="#cb16-6"></a><span class="kw">lines</span>(<span class="dt">x=</span>xGrid, <span class="dt">y=</span>yhat, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">lwd=</span><span class="dv">3</span>)</span></code></pre></div>
<p><img src="sequencing_countData_files/figure-html/unnamed-chunk-6-6.png" width="672" /></p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1"></a><span class="co"># association with hour on count and log scale</span></span>
<span id="cb17-2"><a href="#cb17-2"></a><span class="kw">barplot</span>(<span class="kw">table</span>(Bikeshare<span class="op">$</span>hr), <span class="dt">xlab=</span><span class="st">&quot;Hour of day&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;Number of observations&quot;</span>)</span></code></pre></div>
<p><img src="sequencing_countData_files/figure-html/unnamed-chunk-6-7.png" width="672" /></p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1"></a><span class="kw">plot</span>(bikers <span class="op">~</span><span class="st"> </span>hr, <span class="dt">data=</span>Bikeshare, <span class="dt">pch=</span><span class="dv">16</span>, <span class="dt">cex=</span><span class="dv">1</span><span class="op">/</span><span class="dv">2</span>,</span>
<span id="cb18-2"><a href="#cb18-2"></a>        <span class="dt">xlab =</span> <span class="st">&quot;Hour of day&quot;</span>, <span class="dt">ylab =</span> <span class="st">&quot;Bikers&quot;</span>)</span></code></pre></div>
<p><img src="sequencing_countData_files/figure-html/unnamed-chunk-6-8.png" width="672" /></p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1"></a><span class="kw">plot</span>(<span class="kw">log1p</span>(bikers) <span class="op">~</span><span class="st"> </span>hr, <span class="dt">data=</span>Bikeshare, <span class="dt">pch=</span><span class="dv">16</span>, <span class="dt">cex=</span><span class="dv">1</span><span class="op">/</span><span class="dv">2</span>,</span>
<span id="cb19-2"><a href="#cb19-2"></a>        <span class="dt">xlab =</span> <span class="st">&quot;Hour of day&quot;</span>, <span class="dt">ylab =</span> <span class="st">&quot;Log (bikers +1)&quot;</span>)</span></code></pre></div>
<p><img src="sequencing_countData_files/figure-html/unnamed-chunk-6-9.png" width="672" /></p>
<p>The data exploration shows that</p>
<ul>
<li>More bikes are being used in better weather.</li>
<li>There seems to be a non-linear association between bicycle rentals and humidity, where in both low and high humidity conditions relatively few bikes are used, possibly reflecting very hot and very wet days respectively, while most bikes are being used at moderate humidity.</li>
<li>Bicycle rental is associated with the hour of the day, however, in a non-linear way, with clear peaks in usage at typical commute hours (6h-8h and 17h-19h). Here, we will add <code>hr</code> as a categorical variable to the model, estimating one parameter for each hour. Note that alternative strategies are possible that may be more efficient, such as incorporating <code>hr</code> as a numerical variable and modeling the non-linearity using a lower number of parameters.</li>
<li><em>Disclaimer</em>: Note that there are likely interactions between the variables, which here we will not evaluate as our goal is to introduce a Poisson GLM rather than a full analysis of the <code>Bikeshare</code> dataset. For example, it seems likely that more people commute by bike in good weather, while fewer people will commute by bike in terrible weather. This would motivate an interaction between the variables <code>weathersit</code> and <code>hr</code>.</li>
</ul>
<hr />
<ul>
<li>Below, we fit a Poisson GLM using the <code>glm</code> function. The number of bikers is used as a response variable, which is modeled as a function of <code>weathersit</code>, <code>hum</code> and <code>hr</code>.</li>
<li>Note that there seems to be a non-linear, though fairly simple, association between our response variable and the humidity. We will therefore add a quadratic and cubic term for humidity to the model. In order to avoid multicollinearity between the linear, quadratic and cubic humidity effects, we will first center the humidity variable and store this in a new variable called <code>humc</code>. This means that when <code>humc=0</code>, this corresponds to the average humidity in the dataset.</li>
<li>The argument <code>family = "poisson"</code> specifies the Poisson distribution for the response variable and by default the canonical link function, which is the log link, will be used.</li>
</ul>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1"></a>Bikeshare<span class="op">$</span>humc &lt;-<span class="st"> </span>Bikeshare<span class="op">$</span>hum <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(Bikeshare<span class="op">$</span>hum)</span>
<span id="cb20-2"><a href="#cb20-2"></a>m &lt;-<span class="st"> </span><span class="kw">glm</span>(bikers <span class="op">~</span><span class="st"> </span>weathersit <span class="op">+</span><span class="st"> </span>humc <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(humc<span class="op">^</span><span class="dv">2</span>) <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(humc<span class="op">^</span><span class="dv">3</span>) <span class="op">+</span><span class="st"> </span>hr,</span>
<span id="cb20-3"><a href="#cb20-3"></a>         <span class="dt">data =</span> Bikeshare,</span>
<span id="cb20-4"><a href="#cb20-4"></a>         <span class="dt">family =</span> <span class="st">&quot;poisson&quot;</span>)</span>
<span id="cb20-5"><a href="#cb20-5"></a><span class="kw">summary</span>(m)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = bikers ~ weathersit + humc + I(humc^2) + I(humc^3) + 
##     hr, family = &quot;poisson&quot;, data = Bikeshare)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -23.3408   -4.6201   -0.9922    3.4605   27.4153  
## 
## Coefficients:
##                            Estimate Std. Error  z value Pr(&gt;|z|)    
## (Intercept)                3.893651   0.008083  481.708   &lt;2e-16 ***
## weathersitcloudy/misty    -0.146618   0.002277  -64.401   &lt;2e-16 ***
## weathersitlight rain/snow -0.556153   0.004585 -121.292   &lt;2e-16 ***
## weathersitheavy rain/snow -1.855194   0.166742  -11.126   &lt;2e-16 ***
## humc                       0.091751   0.009233    9.938   &lt;2e-16 ***
## I(humc^2)                 -2.233919   0.029421  -75.929   &lt;2e-16 ***
## I(humc^3)                 -1.823066   0.091428  -19.940   &lt;2e-16 ***
## hr1                       -0.476470   0.012999  -36.654   &lt;2e-16 ***
## hr2                       -0.806959   0.014646  -55.099   &lt;2e-16 ***
## hr3                       -1.433648   0.018842  -76.090   &lt;2e-16 ***
## hr4                       -2.058714   0.024796  -83.027   &lt;2e-16 ***
## hr5                       -1.061695   0.016074  -66.051   &lt;2e-16 ***
## hr6                        0.315691   0.010607   29.761   &lt;2e-16 ***
## hr7                        1.317856   0.009052  145.586   &lt;2e-16 ***
## hr8                        1.830026   0.008653  211.480   &lt;2e-16 ***
## hr9                        1.352135   0.009022  149.871   &lt;2e-16 ***
## hr10                       1.129497   0.009271  121.831   &lt;2e-16 ***
## hr11                       1.308554   0.009102  143.766   &lt;2e-16 ***
## hr12                       1.522234   0.008947  170.131   &lt;2e-16 ***
## hr13                       1.536827   0.008959  171.542   &lt;2e-16 ***
## hr14                       1.499506   0.008999  166.633   &lt;2e-16 ***
## hr15                       1.535043   0.008974  171.062   &lt;2e-16 ***
## hr16                       1.745128   0.008800  198.318   &lt;2e-16 ***
## hr17                       2.140488   0.008565  249.925   &lt;2e-16 ***
## hr18                       2.037740   0.008588  237.279   &lt;2e-16 ***
## hr19                       1.711545   0.008747  195.667   &lt;2e-16 ***
## hr20                       1.393901   0.008976  155.284   &lt;2e-16 ***
## hr21                       1.132543   0.009216  122.895   &lt;2e-16 ***
## hr22                       0.882534   0.009537   92.539   &lt;2e-16 ***
## hr23                       0.481354   0.010207   47.157   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for poisson family taken to be 1)
## 
##     Null deviance: 1052921  on 8644  degrees of freedom
## Residual deviance:  375265  on 8615  degrees of freedom
## AIC: 428362
## 
## Number of Fisher Scoring iterations: 5</code></pre>
<div id="interpretation-of-estimated-model-parameters" class="section level4">
<h4><span class="header-section-number">2.2.3.1</span> Interpretation of estimated model parameters</h4>
<ul>
<li>Remember that the Poisson GLM can be defined as <span class="math display">\[
  \left\{
  \begin{array}{ccc}
  Y_i &amp; \sim &amp; Poi(\mu_i) \\
  \log \mu_i &amp; = &amp; \eta_i \\
  \eta_i &amp; = &amp; \mathbf{X}^T_i \beta \\
  \end{array}
  \right.
  \]</span></li>
</ul>
<p><em>Interpretation of the intercept.</em></p>
<ul>
<li>We will first interpret the intercept, in terms of the average number of bikes being used. Note that the intercept corresponds to hour 0, at good weather (<code>weathersit</code> level 1), and average humidity (<code>humc</code>=0). We will denote the intercept as <span class="math inline">\(\beta_0\)</span> and its estimate as <span class="math inline">\(\hat{\beta}_0\)</span>. All other coefficients will thus denote a relative change with respect to that reference level.</li>
<li>The model definition shows that <span class="math inline">\(\log \mu_i = \mathbf{X}^T_i \mathbf{\beta}\)</span>, with <span class="math inline">\(\mu\)</span> the average number of bikes being used. Since we’re only working with the intercept here, we may write <span class="math inline">\(\log \mu_i = \beta_0\)</span>, and thus <span class="math inline">\(\mu_i = \exp \beta_0\)</span>.</li>
<li>Plugging in the estimated intercept <span class="math inline">\(\hat{\beta}_0\)</span>, we have <span class="math inline">\(\exp \hat{\beta}_0 =\)</span> 49.09. In other words, in clear weather with few clouds, at zero humidity and at hour 0, an average of 49.09 bikes are being used.</li>
</ul>
<hr />
<p><em>Interpretation of <code>weathersitcloudy/misty</code>.</em></p>
<ul>
<li>We will denote this coefficient as <span class="math inline">\(\beta_1\)</span> and its estimate as <span class="math inline">\(\hat{\beta}_1\)</span>.</li>
<li>Note that this coefficient defines the difference in linear predictor between <code>weathersit=2</code> and <code>weathersit=1</code>, all other variables being equal (say, at their reference level). Indeed, define <span class="math inline">\(\eta_{w2}\)</span> and <span class="math inline">\(\eta_{w1}\)</span> to denote the linear predictor at <code>weathersit=2</code>, and <code>weathersit=1</code>, respectively. Then, <span class="math inline">\(\eta_{w2} - \eta_{w1} = (\beta_0 + \beta_1) - \beta_0 = \beta_1\)</span>.</li>
<li>This also means that <span class="math inline">\(\beta_1 = \log \mu_{w2} - \log \mu_{w1} = \log \frac{\mu_{w2}}{\mu_{21}}\)</span>, and thus <span class="math inline">\(\exp \beta_1 = \frac{\mu_{w2}}{\mu_{21}}\)</span>.</li>
<li>In our case, <span class="math inline">\(\exp \hat{\beta}_1 =\)</span> 0.86. In words: All other variables being equal, the average number of bikes being used in cloudy/misty weather is <span class="math inline">\(0.85\)</span> times (or, also, <span class="math inline">\(85\%\)</span> of) the number of bikes being used in good weather.</li>
<li>This exercise has shown us that, <strong>due to the <span class="math inline">\(\log\)</span> link function</strong>, the parameters in a Poisson GLM cannot be interpreted in terms of absolute differences in averages of the response variable but instead must be interpreted in terms of <strong>multiplicative differences</strong>!</li>
<li>If you’re in a meeting and you need a quick way to interpret these parameters, remember that <span class="math inline">\(exp(1) = 2.72 \approx 3\)</span> and thus a difference of <span class="math inline">\(1\)</span> (<span class="math inline">\(-1\)</span>) means the average of the response variable is about three times higher (lower).</li>
</ul>
<hr />
<p><em>Interpretation of the humidity effect.</em></p>
<ul>
<li><p>The humidity effect is a bit more involved to interpret. Due to the quadratic and cubic terms, we cannot interpret the linear term separately (nor can we interpret the quadratic or cubic term separately); we must interpret both the linear, quadratic and cubic term simultaneously.</p></li>
<li><p>Also due to the higher-order terms, the rate of change in average bikers will not be constant across the range of humidity. We can therefore not interpret the humidity effect using a single number as we’ve done previously.</p></li>
<li><p>We can, however, provide some examples for specific humidity values, along with a visualization of its global effect.</p></li>
<li><p>For example, let’s derive the change in average bikes being used at a humidity that is <span class="math inline">\(0.2\)</span> above average, versus average humidity.</p>
<p>For average humidity <span class="math inline">\(+0.2\)</span> the linear predictor <span class="math inline">\(\eta_{0.2} = \beta_0 + \beta_4 x_{hum} + \beta_5 x_{hum}^2 + \beta_6 x_{hum}^3 = \beta_0 + \beta_4 0.2 + \beta_5 0.2^2 + \beta_6 0.2^3\)</span>.</p>
<p>For average humidity, the linear predictor <span class="math inline">\(\eta_{0} = \beta_0 + \beta_4 x_{hum} + \beta_5 x_{hum}^2 + \beta_6 x_{hum}^3 = \beta_0 + \beta_4 0 + \beta_5 0^2 + \beta_6 0^3 = \beta_0\)</span>.</p>
<p>We thus have <span class="math inline">\(\log \frac{\mu_{0.2}}{\mu_0} = \beta_4 0.2 + \beta_5 0.2^2 + \beta_6 0.2^3\)</span>. In our case, <span class="math inline">\(\log \frac{\hat{\mu}_{0.2}}{\hat{\mu}_0} = 0.091751*0.2 - 2.233919 * 0.2^2 - 1.823066 * 0.2^3 = -0.0856\)</span> and thus <span class="math inline">\(\frac{\hat{\mu}_{0.2}}{\hat{\mu}_0} = 0.92\)</span>. Therefore, at humidity that is <span class="math inline">\(0.2\)</span> above average, the average number of bikes being used are <span class="math inline">\(0.92\)</span> times the average number of bikes used at average humidity.</p></li>
<li><p>Just like with linear models, the <code>predict</code> function is extremely helpful when trying to visualize and understand a fitted GLM. In GLMs, the <code>type</code> argument becomes essential when using the <code>predict</code> function. Indeed, by default, estimates are provided on the linear predictor scale: in our case, on the <span class="math inline">\(\log\)</span> scale. If we’d like predictions on the scale of the response variable, we need to set <code>type="response"</code>. You can find more information in the help file using <code>?predict.glm</code>.</p></li>
<li><p>The visualization shows that the highest number of bikes are being used at around average humidity, with a decreased usage at higher and lower humidities.</p></li>
</ul>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1"></a>humidityGrid &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="kw">min</span>(Bikeshare<span class="op">$</span>humc), <span class="kw">max</span>(Bikeshare<span class="op">$</span>humc), </span>
<span id="cb22-2"><a href="#cb22-2"></a>                    <span class="dt">length.out =</span> <span class="dv">50</span>)</span>
<span id="cb22-3"><a href="#cb22-3"></a>newDf &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">weathersit =</span> <span class="kw">factor</span>(<span class="st">&quot;clear&quot;</span>),</span>
<span id="cb22-4"><a href="#cb22-4"></a>                    <span class="dt">hr =</span> <span class="kw">factor</span>(<span class="dv">8</span>),</span>
<span id="cb22-5"><a href="#cb22-5"></a>                    <span class="dt">humc =</span> humidityGrid,</span>
<span id="cb22-6"><a href="#cb22-6"></a>                    <span class="st">&quot;I(humc^2)&quot;</span> =<span class="st"> </span>humidityGrid<span class="op">^</span><span class="dv">2</span>,</span>
<span id="cb22-7"><a href="#cb22-7"></a>                    <span class="st">&quot;I(humc^3)&quot;</span> =<span class="st"> </span>humidityGrid<span class="op">^</span><span class="dv">3</span>)</span>
<span id="cb22-8"><a href="#cb22-8"></a>yhat &lt;-<span class="st"> </span><span class="kw">predict</span>(m, </span>
<span id="cb22-9"><a href="#cb22-9"></a>                <span class="dt">newdata =</span> newDf,</span>
<span id="cb22-10"><a href="#cb22-10"></a>                <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>)</span>
<span id="cb22-11"><a href="#cb22-11"></a></span>
<span id="cb22-12"><a href="#cb22-12"></a><span class="kw">plot</span>(<span class="dt">x =</span> humidityGrid,</span>
<span id="cb22-13"><a href="#cb22-13"></a>     <span class="dt">y =</span> yhat,</span>
<span id="cb22-14"><a href="#cb22-14"></a>     <span class="dt">type =</span> <span class="st">&#39;l&#39;</span>, <span class="dt">lwd=</span><span class="dv">2</span>,</span>
<span id="cb22-15"><a href="#cb22-15"></a>     <span class="dt">xlab =</span> <span class="st">&quot;Centered humidity&quot;</span>,</span>
<span id="cb22-16"><a href="#cb22-16"></a>     <span class="dt">ylab =</span> <span class="st">&quot;Average number of bikers&quot;</span>)</span></code></pre></div>
<p><img src="sequencing_countData_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<hr />
<p><em>Setting up a contrast.</em></p>
<ul>
<li>Suppose we’re interested in whether there are more bikers at (A) maximum humidity (centered humidity value of <span class="math inline">\(0.357\)</span>), hour 17, in the <code>light rain/snow</code> weather category, versus (B) average humidity, hour 8, in the <code>clear</code> weather category. This requires us to set up a contrast in terms of a linear combination of the model parameters.</li>
<li><strong>Manually by hand</strong>: <span class="math display">\[ \log \mu_A = \beta_0 + \beta_2 x_{rainSnow} + \beta_4 x_{hum} + \beta_5 x_{hum}^2 + \beta_6 x_{hum}^3 + \beta_{23} x_{hr17} \\= 3.894 - 0.556 + 0.092 * 0.357 - 2.234 * 0.357^2 - 1.823 * 0.357^3 + 2.140 = 5.143.\\
\log \mu_B = \beta_0 + \beta_{14} x_{hr8} = 3.894 + 1.830 = 5.724.\\
\frac{\mu_A}{\mu_B} = \exp(5.143 - 5.724) = 0.559.
\]</span> Thus, at maximum humidity, hour 17, in the <code>light rain/snow</code> weather category the average number of bikers is 56% times the average number of bikers in the average humidity, hour 8, in the <code>clear</code> weather category.</li>
<li><strong>Manually in <code>R</code></strong>: We can also use matrix multiplication to derive the estimates. We know from our manual calculations above, that the contrast of interest is <span class="math inline">\((\beta_0 + \beta_2 x_{rainSnow} + \beta_4 x_{hum} + \beta_5 x_{hum}^+ \beta_6 x_{hum}^3 + \beta_{23} x_{hr17}) - (\beta_0 + \beta_{14} x_{hr8})\)</span>. We can store this in a contrast matrix, and then multiply it with the coefficients of our model:</li>
</ul>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1"></a>L &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dv">0</span>, </span>
<span id="cb23-2"><a href="#cb23-2"></a>            <span class="dt">nrow =</span> <span class="kw">length</span>(<span class="kw">coef</span>(m)),</span>
<span id="cb23-3"><a href="#cb23-3"></a>            <span class="dt">ncol =</span> <span class="dv">1</span>)</span>
<span id="cb23-4"><a href="#cb23-4"></a><span class="kw">rownames</span>(L) &lt;-<span class="st"> </span><span class="kw">names</span>(<span class="kw">coef</span>(m))</span>
<span id="cb23-5"><a href="#cb23-5"></a>L[<span class="st">&quot;weathersitlight rain/snow&quot;</span>,<span class="dv">1</span>] &lt;-<span class="st"> </span><span class="dv">1</span></span>
<span id="cb23-6"><a href="#cb23-6"></a>L[<span class="st">&quot;humc&quot;</span>,<span class="dv">1</span>] &lt;-<span class="st"> </span><span class="fl">0.357</span></span>
<span id="cb23-7"><a href="#cb23-7"></a>L[<span class="st">&quot;I(humc^2)&quot;</span>, <span class="dv">1</span>] &lt;-<span class="st"> </span><span class="fl">0.357</span><span class="op">^</span><span class="dv">2</span></span>
<span id="cb23-8"><a href="#cb23-8"></a>L[<span class="st">&quot;I(humc^3)&quot;</span>, <span class="dv">1</span>] &lt;-<span class="st"> </span><span class="fl">0.357</span><span class="op">^</span><span class="dv">3</span></span>
<span id="cb23-9"><a href="#cb23-9"></a>L[<span class="st">&quot;hr17&quot;</span>, <span class="dv">1</span>] &lt;-<span class="st"> </span><span class="dv">1</span></span>
<span id="cb23-10"><a href="#cb23-10"></a>L[<span class="st">&quot;hr8&quot;</span>,<span class="dv">1</span>] &lt;-<span class="st"> </span><span class="dv">-1</span></span>
<span id="cb23-11"><a href="#cb23-11"></a>L</span></code></pre></div>
<pre><code>##                                  [,1]
## (Intercept)                0.00000000
## weathersitcloudy/misty     0.00000000
## weathersitlight rain/snow  1.00000000
## weathersitheavy rain/snow  0.00000000
## humc                       0.35700000
## I(humc^2)                  0.12744900
## I(humc^3)                  0.04549929
## hr1                        0.00000000
## hr2                        0.00000000
## hr3                        0.00000000
## hr4                        0.00000000
## hr5                        0.00000000
## hr6                        0.00000000
## hr7                        0.00000000
## hr8                       -1.00000000
## hr9                        0.00000000
## hr10                       0.00000000
## hr11                       0.00000000
## hr12                       0.00000000
## hr13                       0.00000000
## hr14                       0.00000000
## hr15                       0.00000000
## hr16                       0.00000000
## hr17                       1.00000000
## hr18                       0.00000000
## hr19                       0.00000000
## hr20                       0.00000000
## hr21                       0.00000000
## hr22                       0.00000000
## hr23                       0.00000000</code></pre>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1"></a>beta &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">coef</span>(m), <span class="dt">ncol=</span><span class="dv">1</span>)</span>
<span id="cb25-2"><a href="#cb25-2"></a><span class="kw">exp</span>(<span class="kw">t</span>(L) <span class="op">%*%</span><span class="st"> </span>beta) <span class="co"># equals our manual calculation.</span></span></code></pre></div>
<pre><code>##           [,1]
## [1,] 0.5595652</code></pre>
<ul>
<li><strong>Using <code>predict</code> in <code>R</code></strong>:</li>
</ul>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1"></a><span class="co"># set up data frames with relevant predictor variables&#39; values.</span></span>
<span id="cb27-2"><a href="#cb27-2"></a>dfA &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">weathersit =</span> <span class="kw">factor</span>(<span class="st">&quot;light rain/snow&quot;</span>),</span>
<span id="cb27-3"><a href="#cb27-3"></a>                    <span class="dt">hr =</span> <span class="kw">factor</span>(<span class="dv">17</span>),</span>
<span id="cb27-4"><a href="#cb27-4"></a>                    <span class="dt">humc =</span> <span class="fl">0.357</span>,</span>
<span id="cb27-5"><a href="#cb27-5"></a>                    <span class="st">&quot;I(humc^2)&quot;</span> =<span class="st"> </span><span class="fl">0.357</span><span class="op">^</span><span class="dv">2</span>,</span>
<span id="cb27-6"><a href="#cb27-6"></a>                    <span class="st">&quot;I(humc^3)&quot;</span> =<span class="st"> </span><span class="fl">0.357</span><span class="op">^</span><span class="dv">3</span>)</span>
<span id="cb27-7"><a href="#cb27-7"></a>dfB &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">weathersit =</span> <span class="kw">factor</span>(<span class="st">&quot;clear&quot;</span>),</span>
<span id="cb27-8"><a href="#cb27-8"></a>                    <span class="dt">hr =</span> <span class="kw">factor</span>(<span class="dv">8</span>),</span>
<span id="cb27-9"><a href="#cb27-9"></a>                    <span class="dt">humc =</span> <span class="dv">0</span>,</span>
<span id="cb27-10"><a href="#cb27-10"></a>                    <span class="st">&quot;I(humc^2)&quot;</span> =<span class="st"> </span><span class="dv">0</span>,</span>
<span id="cb27-11"><a href="#cb27-11"></a>                    <span class="st">&quot;I(humc^3)&quot;</span> =<span class="st"> </span><span class="dv">0</span>)</span>
<span id="cb27-12"><a href="#cb27-12"></a></span>
<span id="cb27-13"><a href="#cb27-13"></a><span class="co"># calculate estimated average number of bikers</span></span>
<span id="cb27-14"><a href="#cb27-14"></a>yhatA &lt;-<span class="st"> </span><span class="kw">predict</span>(m, </span>
<span id="cb27-15"><a href="#cb27-15"></a>                <span class="dt">newdata =</span> dfA,</span>
<span id="cb27-16"><a href="#cb27-16"></a>                <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>)</span>
<span id="cb27-17"><a href="#cb27-17"></a>yhatB &lt;-<span class="st"> </span><span class="kw">predict</span>(m, </span>
<span id="cb27-18"><a href="#cb27-18"></a>                <span class="dt">newdata =</span> dfB,</span>
<span id="cb27-19"><a href="#cb27-19"></a>                <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>)</span>
<span id="cb27-20"><a href="#cb27-20"></a></span>
<span id="cb27-21"><a href="#cb27-21"></a>yhatA <span class="op">/</span><span class="st"> </span>yhatB <span class="co"># also equal to above.</span></span></code></pre></div>
<pre><code>##         1 
## 0.5595652</code></pre>
<hr />
<p><strong>Exercise</strong>: try to derive the change in average number of bikers between (a) humidity of 0.1 above average, clear weather (<code>weathersit=1</code>), at hour 10 and (b) humidity of 0.1 below average, cloudy weather (<code>weathersit=2</code>), at hour 20, using all three methods.</p>
</div>
</div>
</div>
<div id="statistical-inference-in-glms" class="section level2">
<h2><span class="header-section-number">2.3</span> Statistical inference in GLMs</h2>
<div id="wald-test-and-likelihood-ratio-test" class="section level3">
<h3><span class="header-section-number">2.3.1</span> Wald test and likelihood ratio test</h3>
<ul>
<li>In our interpretation above we have focussed on deriving changes in the average number of bikers between groups of interest. However, we have not yet tested whether these changes are statistically significant.</li>
<li>In genomics applications, statistical inference in GLMs is often adopted to test for differential expression between conditions for each gene (e.g., <em>is gene A differently expressed in healthy versus tumoral tissue?</em>), which amounts to testing the null hypothesis of whether a (linear combination of) coefficient(s) equals zero.</li>
<li>In this course, we will mainly work with two types of statistical tests for GLMs:
<ul>
<li><strong>Wald test</strong>: The Wald test may be viewed as being anaologous to the <span class="math inline">\(t\)</span>-test we are using in linear models. The Wald test relies on the following asymptotic result <span class="math display">\[\hat{\beta} | \beta \sim N (\beta, Var(\hat{\beta}))\]</span>. The Wald test statistic for testing a single parameter <span class="math inline">\(\hat{\beta}\)</span> <span class="math display">\[W = \frac{\hat{\beta}}{\hat{SE}(\hat{\beta})} \sim N(0,1) | H_0\]</span> or, equivalently, letting <span class="math inline">\(\mathbf{C}\)</span> denote the <span class="math inline">\(1 \times p\)</span> contrast matrix denoting the contrast for the single parameter <span class="math inline">\(\beta\)</span> we would like to test, and <span class="math inline">\(\hat{\Sigma}_{\hat{\beta}}\)</span> the <span class="math inline">\(p \times p\)</span> variance-covariance matrix of the parameters, <span class="math display">\[W = \mathbf{C}\hat{\beta} (\mathbf{C} \hat{\Sigma}_{\hat{\beta}} \mathbf{C}^T)^{-1} \hat{\beta}^T \mathbf{C}^T \sim \chi^2_1 | H_0.\]</span> The null and alternative hypothesis can therefore in general be written as <span class="math display">\[ H_0: \mathbf{C}\hat{\beta} = 0\]</span> <span class="math display">\[ H_1: \mathbf{C}\hat{\beta} \ne 0\]</span> If <span class="math inline">\(c \ge 1\)</span> contrasts are tested, then the test statistic <span class="math inline">\(W \sim \chi^2_c | H_0\)</span>, provided that the <span class="math inline">\(c\)</span> contrasts are linearly independent (i.e., the contrast matrix is full rank).</li>
<li><strong>Likelihood ratio test</strong>: The likelihood ratio test (LRT) measures the discrepancy in log-likelihood between our current model (sometimes also referred to as full model) and a reduced model (sometimes also referred to as null or alternative model). The reduced model must be nested in (and therefore of lower dimension as compared to) the full model. While adding more covariates will always explain more variability in our response variable, the LRT tests whether this is actually significant. For example, in the example of gene differential expression between healthy versus tumoral tissue, the full model could be a GLM where the mean is modeled according to an intercept and a tissue indicator variable (healthy / tumoral), while the alternative model could be a GLM with just an intercept. Indeed, if the gene is similarly expressed between healthy and tumoral tissue, the log-likelihood of the alternative model will decrease only a little as compared to the full model. As the name suggests, the likelihood ratio test assesses whether the ratio of the log-likelihoods provides sufficient evidence for a worse fit of the alternative versus full model <span class="math display">\[L = 2 \log \left\{ \ell(\hat{\beta}_{full}) -  \ell(\hat{\beta}_{alternative}) \right\}.\]</span> Asymptotically, under the null hypothesis it can be shown that <span class="math display">\[ L \sim \chi_c^2 | H_0, \]</span> with <span class="math inline">\(c\)</span> the number of parameters dropped in the alternative model versus the full model. If we again let <span class="math inline">\(\mathbf{C}\)</span> denote the <span class="math inline">\(c \times p\)</span> contrast matrix denoting the contrast for the parameters being dropped, the null and alternative hypothesis are as in the Wald test setting: <span class="math display">\[ H_0: \mathbf{C}\hat{\beta} = 0\]</span> <span class="math display">\[ H_1: \mathbf{C}\hat{\beta} \ne 0\]</span> Finally, note that while, in this explanation, I have focussed on reducing a more complex model, but of course the LRT can also be adopted to check whether adding a covariate significantly improves the fit.</li>
</ul></li>
<li>It is important to keep in mind that standard statistical inference theory in GLMs works <strong>asymptotically in terms of the sample size</strong>. Thus we need many data points in order for the theory to hold in practice. In order for the <span class="math inline">\(p\)</span>-values to be correct, our parametric (distributional) assumptions as well as the independence assumption, must also hold.</li>
<li>In bulk RNA-seq, we are often working with a limited number of samples and so we typically do not expect asymptotic theory to hold yet. In single-cell RNA-seq, we often perform several preprocessing steps before calculating <span class="math inline">\(p\)</span>-values for each gene and so we may be ‘using the data multiple times’. Rather than attaching strong probabilistic interpretations to the <span class="math inline">\(p\)</span>-values, we therefore advice to view the <span class="math inline">\(p\)</span>-values simply as useful numerical summaries for ranking the genes for further inspection in genomics applications.</li>
</ul>
<p><strong>TODO: add schematic comparing Wald with LRT using log-likelihood function</strong></p>
</div>
<div id="wald-test-and-likelihood-ratio-test-in-r" class="section level3">
<h3><span class="header-section-number">2.3.2</span> Wald test and likelihood ratio test in <code>R</code></h3>
<p>Let’s use a Wald test and a likelihood ratio test to test whether the average number of bikers differs between a working day or a weekend day, using a simple GLM with only that variable as a covariate. This amounts to testing</p>
<p><span class="math display">\[H_0: \beta_{workingday} = 0\]</span> <span class="math display">\[H_1: \beta_{workingday} \ne 0\]</span></p>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1"></a>mSimple &lt;-<span class="st"> </span><span class="kw">glm</span>(bikers <span class="op">~</span><span class="st"> </span>workingday, </span>
<span id="cb29-2"><a href="#cb29-2"></a>               <span class="dt">family =</span> <span class="st">&quot;poisson&quot;</span>, </span>
<span id="cb29-3"><a href="#cb29-3"></a>               <span class="dt">data =</span> Bikeshare)</span>
<span id="cb29-4"><a href="#cb29-4"></a>summSimple &lt;-<span class="st"> </span><span class="kw">summary</span>(mSimple)</span>
<span id="cb29-5"><a href="#cb29-5"></a>summSimple<span class="op">$</span>coefficients[<span class="st">&quot;workingday&quot;</span>,]</span></code></pre></div>
<pre><code>##     Estimate   Std. Error      z value     Pr(&gt;|z|) 
## 2.352087e-02 1.937241e-03 1.214143e+01 6.370326e-34</code></pre>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1"></a><span class="co"># Wald test manually</span></span>
<span id="cb31-2"><a href="#cb31-2"></a>W &lt;-<span class="st"> </span>summSimple<span class="op">$</span>coefficients[<span class="st">&quot;workingday&quot;</span>, <span class="st">&quot;Estimate&quot;</span>] <span class="op">/</span><span class="st"> </span>summSimple<span class="op">$</span>coefficients[<span class="st">&quot;workingday&quot;</span>, <span class="st">&quot;Std. Error&quot;</span>]</span>
<span id="cb31-3"><a href="#cb31-3"></a>pval &lt;-<span class="st"> </span><span class="dv">2</span><span class="op">*</span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">pnorm</span>(W))</span>
<span id="cb31-4"><a href="#cb31-4"></a>W</span></code></pre></div>
<pre><code>## [1] 12.14143</code></pre>
<div class="sourceCode" id="cb33"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1"></a>pval</span></code></pre></div>
<pre><code>## [1] 0</code></pre>
<div class="sourceCode" id="cb35"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1"></a><span class="co"># Wald test through a contrast</span></span>
<span id="cb35-2"><a href="#cb35-2"></a>C &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dv">0</span>, <span class="dt">nrow=</span><span class="dv">1</span>, <span class="dt">ncol=</span><span class="kw">length</span>(<span class="kw">coef</span>(mSimple)))</span>
<span id="cb35-3"><a href="#cb35-3"></a><span class="kw">colnames</span>(C) &lt;-<span class="st"> </span><span class="kw">names</span>(<span class="kw">coef</span>(mSimple))</span>
<span id="cb35-4"><a href="#cb35-4"></a>C[, <span class="st">&quot;workingday&quot;</span>] &lt;-<span class="st"> </span><span class="dv">1</span></span>
<span id="cb35-5"><a href="#cb35-5"></a>beta &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">coef</span>(mSimple), <span class="dt">ncol=</span><span class="dv">1</span>)</span>
<span id="cb35-6"><a href="#cb35-6"></a>Sigma &lt;-<span class="st"> </span><span class="kw">vcov</span>(mSimple)</span>
<span id="cb35-7"><a href="#cb35-7"></a></span>
<span id="cb35-8"><a href="#cb35-8"></a>W2 &lt;-<span class="st"> </span>C <span class="op">%*%</span><span class="st"> </span>beta <span class="op">%*%</span><span class="st"> </span><span class="kw">solve</span>(C <span class="op">%*%</span><span class="st"> </span>Sigma <span class="op">%*%</span><span class="st"> </span><span class="kw">t</span>(C)) <span class="op">%*%</span><span class="st"> </span><span class="kw">t</span>(beta) <span class="op">%*%</span><span class="st"> </span><span class="kw">t</span>(C)</span>
<span id="cb35-9"><a href="#cb35-9"></a>W2</span></code></pre></div>
<pre><code>##          [,1]
## [1,] 147.4143</code></pre>
<div class="sourceCode" id="cb37"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1"></a><span class="co"># note this being equal to</span></span>
<span id="cb37-2"><a href="#cb37-2"></a>W<span class="op">^</span><span class="dv">2</span></span></code></pre></div>
<pre><code>## [1] 147.4143</code></pre>
<div class="sourceCode" id="cb39"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1"></a>pval &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">-</span><span class="kw">pchisq</span>(W, <span class="dt">df=</span><span class="dv">1</span>)</span>
<span id="cb39-2"><a href="#cb39-2"></a>pval</span></code></pre></div>
<pre><code>## [1] 0.0004931396</code></pre>
<div class="sourceCode" id="cb41"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1"></a><span class="co"># finally, we can also read the Wald test result from the summary of the model</span></span>
<span id="cb41-2"><a href="#cb41-2"></a>summSimple</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = bikers ~ workingday, family = &quot;poisson&quot;, data = Bikeshare)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -16.666  -11.361   -3.026    5.214   30.729  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept) 4.952243   0.001608 3080.12   &lt;2e-16 ***
## workingday  0.023521   0.001937   12.14   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for poisson family taken to be 1)
## 
##     Null deviance: 1052921  on 8644  degrees of freedom
## Residual deviance: 1052773  on 8643  degrees of freedom
## AIC: 1105815
## 
## Number of Fisher Scoring iterations: 5</code></pre>
<div class="sourceCode" id="cb43"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1"></a>mFull &lt;-<span class="st"> </span><span class="kw">glm</span>(bikers <span class="op">~</span><span class="st"> </span>workingday, </span>
<span id="cb43-2"><a href="#cb43-2"></a>               <span class="dt">family =</span> <span class="st">&quot;poisson&quot;</span>, </span>
<span id="cb43-3"><a href="#cb43-3"></a>               <span class="dt">data =</span> Bikeshare)</span>
<span id="cb43-4"><a href="#cb43-4"></a></span>
<span id="cb43-5"><a href="#cb43-5"></a>mReduced &lt;-<span class="st"> </span><span class="kw">glm</span>(bikers <span class="op">~</span><span class="st"> </span><span class="dv">1</span>, </span>
<span id="cb43-6"><a href="#cb43-6"></a>               <span class="dt">family =</span> <span class="st">&quot;poisson&quot;</span>, </span>
<span id="cb43-7"><a href="#cb43-7"></a>               <span class="dt">data =</span> Bikeshare)</span>
<span id="cb43-8"><a href="#cb43-8"></a></span>
<span id="cb43-9"><a href="#cb43-9"></a><span class="co"># manual LRT</span></span>
<span id="cb43-10"><a href="#cb43-10"></a>llFull &lt;-<span class="st"> </span><span class="kw">logLik</span>(mFull)</span>
<span id="cb43-11"><a href="#cb43-11"></a>llReduced &lt;-<span class="st"> </span><span class="kw">logLik</span>(mReduced)</span>
<span id="cb43-12"><a href="#cb43-12"></a></span>
<span id="cb43-13"><a href="#cb43-13"></a>lrt &lt;-<span class="st"> </span><span class="kw">as.numeric</span>(<span class="dv">2</span> <span class="op">*</span><span class="st"> </span>(llFull <span class="op">-</span><span class="st"> </span>llReduced))</span>
<span id="cb43-14"><a href="#cb43-14"></a>lrt</span></code></pre></div>
<pre><code>## [1] 147.8481</code></pre>
<div class="sourceCode" id="cb45"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb45-1"><a href="#cb45-1"></a>pval &lt;-<span class="st"> </span><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">pchisq</span>(lrt, <span class="dt">df=</span><span class="dv">1</span>)</span>
<span id="cb45-2"><a href="#cb45-2"></a>pval</span></code></pre></div>
<pre><code>## [1] 0</code></pre>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb47-1"><a href="#cb47-1"></a><span class="co"># using anova function</span></span>
<span id="cb47-2"><a href="#cb47-2"></a><span class="kw">anova</span>(mReduced, mFull, <span class="dt">test =</span> <span class="st">&quot;Chisq&quot;</span>) <span class="co"># note test statistic is identical</span></span></code></pre></div>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":[""],"name":["_rn_"],"type":[""],"align":["left"]},{"label":["Resid. Df"],"name":[1],"type":["dbl"],"align":["right"]},{"label":["Resid. Dev"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["Df"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["Deviance"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["Pr(>Chi)"],"name":[5],"type":["dbl"],"align":["right"]}],"data":[{"1":"8644","2":"1052921","3":"NA","4":"NA","5":"NA","_rn_":"1"},{"1":"8643","2":"1052773","3":"1","4":"147.8481","5":"5.120781e-34","_rn_":"2"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
</div>
</div>
<div id="model-deviance-residuals-and-goodness-of-fit" class="section level2">
<h2><span class="header-section-number">2.4</span> Model deviance, residuals and goodness-of-fit</h2>
<ul>
<li>In linear models, we often use residuals <span class="math inline">\(e_i = y_i - \hat{\mu}_i\)</span> to check model assumptions (linearity, homoscedasticity). However, in a GLM setting, we know that the variance of our residuals will depend on the mean, i.e., <span class="math inline">\(Var(\epsilon_i) = f(\mu_i)\)</span>. Using ordinary residuals such as <span class="math inline">\(e_i\)</span> therefore is no longer appropriate.</li>
<li>We have seen that the objective function that is used to fit a GLM is the log-likelihood of the data under the posited model. For example, the log likelihood of a Poisson GLM with response variable <span class="math inline">\(\mathbf{Y}\)</span>, with elements <span class="math inline">\(Y_i, i \in \{1, \ldots, n\}\)</span> and model matrix <span class="math inline">\(\mathbf{X}\)</span> is <span class="math display">\[ \ell(\mathbf{Y};  \beta) = \log \prod_{i=1}^n \left( \frac{\exp (\mathbf{X}_i^T \beta)^{Y_i} \exp( - \exp(\mathbf{X}_i^T \beta))}{Y_i!} \right) = \sum_{i=1}^n \log \left( \frac{\exp(\mathbf{X}_i^T \beta)^{Y_i} \exp( - \exp(\mathbf{X}_i^T \beta))}{Y_i!} \right) \\ = \sum_{i=1}^n Y_i (\mathbf{X}_i^T \beta) + \exp(\mathbf{X}_i^T \beta)  - \log Y_i!. \]</span> The estimates <span class="math inline">\(\hat{\beta}\)</span> are then found by maximizing <span class="math inline">\(\ell(\beta | \mathbf{Y}, \mathbf{X} )\)</span> with respect to <span class="math inline">\(\beta\)</span>. This is analogous to maximizing a Gaussian likelihood in the linear model setting.</li>
<li>A goodness-of-fit measure used in the GLM setting is the <strong>residual deviance</strong> <span class="math inline">\(D\)</span> (sometimes referred to simply as ‘deviance’), that is twice the difference in log-likelihood between a ‘saturated model’ and the current model. Here, a saturated model, is a model where we fit one parameter per data point and therefore fit the data perfectly, in other words <span class="math inline">\(\hat{\mu}_i = y_i\)</span>. This is, <span class="math display">\[ D = 2 * \left\{ \ell(\mathbf{Y};  \beta | \hat{\mu}_i = y_i) - \ell(\mathbf{Y};  \beta | \hat{\mu}_i = \exp(\mathbf{X}_i^T \beta)) \right\}.\]</span></li>
<li>From the equation above it becomes clear that the residual deviance is actually a ratio in log-likelihoods and therefore a likelihood ratio test statistic!</li>
<li>A low residual deviance can thus be interpreted as a model that is fitting the data well, since your current model will be close in log-likelihood to the saturated model. The deviance is a very useful statistic that is also important in statistical inference and model selection, e.g., for testing if a smaller model fits significantly worse than a larger model.</li>
<li>Finally, a <strong>deviance residual</strong> <span class="math inline">\(D_i\)</span> can then be defined as the square root of the contribution of the <span class="math inline">\(i\)</span>th datum to the residual deviance <span class="math display">\[ D_i = \sqrt{ 2* \left\{ \ell(Y_i;  \beta | \hat{\mu}_i = y_i) - \ell(Y_i;  \beta | \hat{\mu}_i = \exp(\mathbf{X}_i^T \beta)) \right\} } \]</span></li>
</ul>
<hr />
<ul>
<li>Another type of residuals commonly used in a GLM setting are <strong>Pearson residuals</strong>. A Pearson residual is defined as <span class="math display">\[ e_i = \frac{y_i - \hat{\mu}_i}{\sqrt{Var(\hat{\mu}_i)}},\]</span> and we can see that it has the form of a regular residual such as used in liner models (numerator), but normalized according to the variance of the estimated mean (denominator), to correct for the mean-variance relationship.</li>
</ul>
<hr />
<ul>
<li><strong>Goodness-of-fit</strong> (GOF) analyses serve to assess how well the model actually fits the observed data. One may view the fitting of a GLM as replacing a set of observed data points <span class="math inline">\(\mathbf{y}\)</span> by a set of fitted values <span class="math inline">\(\hat{\mathbf{\mu}}\)</span> derived from a model. In general <span class="math inline">\(\hat{\mathbf{\mu}} \ne \mathbf{y}\)</span> and the question arises as to how well <span class="math inline">\(\hat{\mathbf{\mu}}\)</span> approximates <span class="math inline">\(\mathbf{y}\)</span>. This naturally raises the question of how much of a discrepancy we believe to be tolerable. Two important discrepancy measures are often used in a GLM setting.</li>
<li>Note that the <strong>residual deviance</strong> was a likelihood ratio test statistic between a saturated and our current model. This saturated model actually provides us with a baseline as to how well a model can fit the observed data (even if we know that the saturated model is uninformative for summarizing the data). This motivates a statistical test with<br />
<span class="math inline">\(H_0\)</span>: The current model provides a similar fit as the saturated model.<br />
<span class="math inline">\(H_1\)</span>: The current model fits significantly worse than a saturated model.<br />
</li>
<li>The residual deviance immediately tests this hypothesis using a likelihood ratio test and is therefore a useful goodness-of-fit measure.</li>
<li>Another measure of discrepancy is the generalized Pearson <span class="math inline">\(\chi^2\)</span> statistic <span class="math display">\[ X^2 = \sum_{i=1}^n \frac{(y_i - \hat{\mu}_i)^2}{Var(\hat{\mu}_i)} = \sum_{i=1}^n e_i^2,\]</span> with <span class="math inline">\(e_i\)</span> the Pearson residual of observation <span class="math inline">\(i\)</span>.</li>
<li>Asymptotic theory shows that both the residual deviance <span class="math inline">\(D \sim \chi^2_{n-p} | H_0\)</span> and <span class="math inline">\(X^2 \sim \chi^2_{n-p} | H_0\)</span>, with <span class="math inline">\(n\)</span> the number of observations in our dataset (and, hence, the number of parameters fitted in our saturated model), and <span class="math inline">\(p\)</span> the number of parameters fitted in our current model.</li>
</ul>
<hr />
<p><strong>Exercise</strong>:</p>
<ul>
<li>Verify the residual deviance that is reported in the summary of our model above.</li>
<li>Also check if you can recover the correct deviance and Pearson residuals by calculating them yourself. You can get the correct deviance residuals in <code>R</code> by <code>resid(m, type="deviance")</code> and <code>resid(m, type="pearson")</code>.</li>
<li>Does your model fit significantly worse than a saturated model?</li>
</ul>
</div>
<div id="overdispersion" class="section level2">
<h2><span class="header-section-number">2.5</span> Overdispersion</h2>
<ul>
<li>Above we have always assumed that the Poisson distribution is valid for the dataset we have been using. However, we never checked for this.</li>
<li>As a matter of fact, it often happens that the variance=mean assumption is too stringent for count data. If the variance is larger than the mean, this is referred to as <strong>overdispersion</strong>. Though much less common, underdispersion happens when the variance is smaller than the mean.</li>
<li>We can use Pearson residuals to measure overdispersion using the following argument. The Poisson GLM implies that <span class="math display">\[ Y_i | X_i, \hat{\beta} \sim Poi(\hat{\mu}_i),\]</span> with <span class="math inline">\(\hat{\mu}_i = \exp (\mathbf{X}_i^T \hat{\beta})\)</span>. This implies <span class="math display">\[ Var(Y_i | X, \hat{\beta}) = \hat{\mu}_i.\]</span> Since the variance is unaffected by addition we may also write <span class="math display">\[ Var(Y_i - \hat{\mu}_i | X, \hat{\beta}) = \hat{\mu}_i.\]</span> Which is also equal to <span class="math display">\[ Var\left(\frac{Y_i - \hat{\mu}_i}{\sqrt{Var(\hat{\mu}_i)}} | X, \hat{\beta} \right) = \frac{\hat{\mu}_i}{Var(\hat{\mu}_i)}.\]</span> Since we know from the Poisson distribution that <span class="math inline">\(Var(\hat{\mu}_i) = \hat{\mu}_i\)</span>, we have that <span class="math display">\[ Var \left(\frac{Y_i - \hat{\mu}_i}{\sqrt{\hat{\mu}_i}} | X, \hat{\beta} \right) = \frac{\hat{\mu}_i}{\hat{\mu}_i}.\]</span> Note that the formulation within the variance at left-hand side of the equation is our definition of Pearson residuals <span class="math inline">\(E_i\)</span>. Thus, if the Poisson assumption holds, we can write <span class="math display">\[ Var(E_i | X, \hat{\beta}) = 1,\]</span> which is something we can empirically test using our fitted model. Indeed, <strong>if the variance of our Pearson residuals is much larger than <span class="math inline">\(1\)</span>, we are dealing with overdispersion</strong>. As a rough rule, I consider overdispersion to be present if this value is larger than <span class="math inline">\(\sim 1.3\)</span>, but this is arbitrary and may depend on the situation (and statistician).</li>
</ul>
<hr />
<ul>
<li>Below, we apply this to the <code>Bikeshare</code> dataset. We will notice that the overdispersion is huge! The p-values and standard errors provided by the model can therefore not be trusted!</li>
</ul>
<div class="sourceCode" id="cb48"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb48-1"><a href="#cb48-1"></a>ePearson &lt;-<span class="st"> </span><span class="kw">resid</span>(m, <span class="dt">type=</span><span class="st">&quot;pearson&quot;</span>)</span>
<span id="cb48-2"><a href="#cb48-2"></a>n &lt;-<span class="st"> </span><span class="kw">nrow</span>(Bikeshare)</span>
<span id="cb48-3"><a href="#cb48-3"></a>p &lt;-<span class="st"> </span><span class="kw">length</span>(<span class="kw">coef</span>(m))</span>
<span id="cb48-4"><a href="#cb48-4"></a>varPearson &lt;-<span class="st"> </span><span class="kw">sum</span>((ePearson<span class="op">^</span><span class="dv">2</span>)) <span class="op">/</span><span class="st"> </span>(n <span class="op">-</span><span class="st"> </span>p)</span>
<span id="cb48-5"><a href="#cb48-5"></a>varPearson <span class="co"># HUGE!</span></span></code></pre></div>
<pre><code>## [1] 42.44815</code></pre>
<div id="remedies-to-overdispersion" class="section level3">
<h3><span class="header-section-number">2.5.1</span> Remedies to overdispersion</h3>
<ul>
<li>The presence of overdispersion tells us that the distributional assumption we have been making does not hold. Overdispersion is a common problem, and luckily we have a few available remedies, as in alternative distributions, although choosing between them may not always be trival.
<ul>
<li>The <strong>negative binomial</strong> (NB) distribution is a popular choice for modeling data that are overdispersed with respect to the Poisson distribution. The NB can be considered as a member of the exponential family and therefore fitted using standard GLM fitting engines. Just like the Poisson distribution, it is a distribution only appropriate for modeling count data. If <span class="math display">\[ Y_i \sim NB(\mu_i, \phi), \]</span> then <span class="math inline">\(E(Y_i) = \mu_i\)</span> and <span class="math inline">\(Var(Y_i) = \mu_i + \phi \mu_i^2\)</span>, with <span class="math inline">\(\phi \ge 0\)</span> the <strong>dispersion parameter</strong>. Since <span class="math inline">\(\phi \ge 0\)</span> the variance of the negative binomial is always larger than that of the Poisson distribution, and in fact is now a quadratic (rather than linear) function of the mean. When <span class="math inline">\(\phi = 0\)</span>, the NB reduces to the Poisson distribution.</li>
<li>The <strong>quasi-Poisson</strong> model is an alternative choice derived using the quasi-likelihood framework developed by <a href="https://www.jstor.org/stable/2334725?seq=1#metadata_info_tab_contents">Wedderburn (1974)</a>. However, only the first two moments (mean and variance) are specified, and all other moments are left unspecified. In particular if model <span class="math inline">\(Y_i\)</span> using a quasi-Poisson model, then <span class="math inline">\(E(Y_i) = \mu_i\)</span> and <span class="math inline">\(Var(Y_i) = \phi \mu_i\)</span>, with <span class="math inline">\(\phi \ge 0\)</span> the <strong>(quasi-)dispersion parameter</strong>. Again, since <span class="math inline">\(\phi \ge 0\)</span> the variance of the quasi-Poisson is always larger than that of the Poisson distribution, however, the dispersion parameter here is on the linear scale, and so the mean-variance relationship is still linear as opposed to quadratic in the NB.</li>
</ul></li>
</ul>
<hr />
<p>Below, we fit a negative binomial and quasi-Poisson model in <code>R</code>.</p>
<div class="sourceCode" id="cb50"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb50-1"><a href="#cb50-1"></a><span class="co">## negative binomial</span></span>
<span id="cb50-2"><a href="#cb50-2"></a><span class="kw">library</span>(MASS)</span>
<span id="cb50-3"><a href="#cb50-3"></a>mNB &lt;-<span class="st"> </span><span class="kw">glm.nb</span>(bikers <span class="op">~</span><span class="st"> </span>weathersit <span class="op">+</span><span class="st"> </span>humc <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(humc<span class="op">^</span><span class="dv">2</span>) <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(humc<span class="op">^</span><span class="dv">3</span>) <span class="op">+</span><span class="st"> </span>hr,</span>
<span id="cb50-4"><a href="#cb50-4"></a>         <span class="dt">data =</span> Bikeshare)</span>
<span id="cb50-5"><a href="#cb50-5"></a><span class="kw">summary</span>(mNB)</span></code></pre></div>
<pre><code>## 
## Call:
## glm.nb(formula = bikers ~ weathersit + humc + I(humc^2) + I(humc^3) + 
##     hr, data = Bikeshare, init.theta = 2.420957542, link = log)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -4.0170  -0.9246  -0.1729   0.5008   5.4746  
## 
## Coefficients:
##                           Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)                3.86978    0.03560 108.701  &lt; 2e-16 ***
## weathersitcloudy/misty    -0.15215    0.01753  -8.681  &lt; 2e-16 ***
## weathersitlight rain/snow -0.62708    0.02956 -21.212  &lt; 2e-16 ***
## weathersitheavy rain/snow -1.95785    0.66526  -2.943  0.00325 ** 
## humc                       0.22567    0.06968   3.239  0.00120 ** 
## I(humc^2)                 -1.95867    0.20007  -9.790  &lt; 2e-16 ***
## I(humc^3)                 -0.75361    0.59317  -1.270  0.20391    
## hr1                       -0.47370    0.04968  -9.535  &lt; 2e-16 ***
## hr2                       -0.79592    0.05041 -15.789  &lt; 2e-16 ***
## hr3                       -1.42636    0.05216 -27.346  &lt; 2e-16 ***
## hr4                       -2.04660    0.05478 -37.360  &lt; 2e-16 ***
## hr5                       -1.05264    0.05085 -20.701  &lt; 2e-16 ***
## hr6                        0.32952    0.04909   6.712 1.92e-11 ***
## hr7                        1.33266    0.04868  27.375  &lt; 2e-16 ***
## hr8                        1.86123    0.04862  38.283  &lt; 2e-16 ***
## hr9                        1.38427    0.04877  28.382  &lt; 2e-16 ***
## hr10                       1.14603    0.04900  23.390  &lt; 2e-16 ***
## hr11                       1.32835    0.04913  27.035  &lt; 2e-16 ***
## hr12                       1.54916    0.04934  31.401  &lt; 2e-16 ***
## hr13                       1.56716    0.04951  31.655  &lt; 2e-16 ***
## hr14                       1.53797    0.04960  31.010  &lt; 2e-16 ***
## hr15                       1.57197    0.04961  31.689  &lt; 2e-16 ***
## hr16                       1.78550    0.04947  36.092  &lt; 2e-16 ***
## hr17                       2.19094    0.04924  44.491  &lt; 2e-16 ***
## hr18                       2.08597    0.04911  42.473  &lt; 2e-16 ***
## hr19                       1.75147    0.04890  35.816  &lt; 2e-16 ***
## hr20                       1.41815    0.04883  29.044  &lt; 2e-16 ***
## hr21                       1.14329    0.04875  23.450  &lt; 2e-16 ***
## hr22                       0.89344    0.04879  18.313  &lt; 2e-16 ***
## hr23                       0.49606    0.04891  10.142  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for Negative Binomial(2.421) family taken to be 1)
## 
##     Null deviance: 26632.4  on 8644  degrees of freedom
## Residual deviance:  9314.9  on 8615  degrees of freedom
## AIC: 93224
## 
## Number of Fisher Scoring iterations: 1
## 
## 
##               Theta:  2.4210 
##           Std. Err.:  0.0374 
## 
##  2 x log-likelihood:  -93161.6150</code></pre>
<div class="sourceCode" id="cb52"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb52-1"><a href="#cb52-1"></a><span class="kw">mean</span>(<span class="kw">resid</span>(mNB, <span class="dt">type =</span> <span class="st">&quot;pearson&quot;</span>)<span class="op">^</span><span class="dv">2</span>) <span class="co"># no more overdispersion!</span></span></code></pre></div>
<pre><code>## [1] 0.9833573</code></pre>
<div class="sourceCode" id="cb54"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb54-1"><a href="#cb54-1"></a><span class="co">## quasi-Poisson</span></span>
<span id="cb54-2"><a href="#cb54-2"></a>mQP &lt;-<span class="st"> </span><span class="kw">glm</span>(bikers <span class="op">~</span><span class="st"> </span>weathersit <span class="op">+</span><span class="st"> </span>humc <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(humc<span class="op">^</span><span class="dv">2</span>) <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(humc<span class="op">^</span><span class="dv">3</span>) <span class="op">+</span><span class="st"> </span>hr,</span>
<span id="cb54-3"><a href="#cb54-3"></a>         <span class="dt">data =</span> Bikeshare,</span>
<span id="cb54-4"><a href="#cb54-4"></a>         <span class="dt">family=</span><span class="st">&quot;quasipoisson&quot;</span>)</span>
<span id="cb54-5"><a href="#cb54-5"></a><span class="co"># note the dispersion parameter being estimated is equal to our overdispersion diagnostic measure. </span></span>
<span id="cb54-6"><a href="#cb54-6"></a><span class="co"># Indeed, this is the way the dispersion parameter is estimated for the QP!!</span></span>
<span id="cb54-7"><a href="#cb54-7"></a><span class="kw">summary</span>(mQP) </span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = bikers ~ weathersit + humc + I(humc^2) + I(humc^3) + 
##     hr, family = &quot;quasipoisson&quot;, data = Bikeshare)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -23.3408   -4.6201   -0.9922    3.4605   27.4153  
## 
## Coefficients:
##                           Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)                3.89365    0.05266  73.936  &lt; 2e-16 ***
## weathersitcloudy/misty    -0.14662    0.01483  -9.885  &lt; 2e-16 ***
## weathersitlight rain/snow -0.55615    0.02987 -18.617  &lt; 2e-16 ***
## weathersitheavy rain/snow -1.85519    1.08636  -1.708  0.08773 .  
## humc                       0.09175    0.06015   1.525  0.12723    
## I(humc^2)                 -2.23392    0.19169 -11.654  &lt; 2e-16 ***
## I(humc^3)                 -1.82307    0.59568  -3.060  0.00222 ** 
## hr1                       -0.47647    0.08469  -5.626 1.90e-08 ***
## hr2                       -0.80696    0.09542  -8.457  &lt; 2e-16 ***
## hr3                       -1.43365    0.12276 -11.679  &lt; 2e-16 ***
## hr4                       -2.05871    0.16155 -12.744  &lt; 2e-16 ***
## hr5                       -1.06169    0.10473 -10.138  &lt; 2e-16 ***
## hr6                        0.31569    0.06911   4.568 4.99e-06 ***
## hr7                        1.31786    0.05898  22.346  &lt; 2e-16 ***
## hr8                        1.83003    0.05638  32.459  &lt; 2e-16 ***
## hr9                        1.35214    0.05878  23.003  &lt; 2e-16 ***
## hr10                       1.12950    0.06040  18.699  &lt; 2e-16 ***
## hr11                       1.30855    0.05930  22.066  &lt; 2e-16 ***
## hr12                       1.52223    0.05829  26.113  &lt; 2e-16 ***
## hr13                       1.53683    0.05837  26.329  &lt; 2e-16 ***
## hr14                       1.49951    0.05863  25.576  &lt; 2e-16 ***
## hr15                       1.53504    0.05846  26.256  &lt; 2e-16 ***
## hr16                       1.74513    0.05733  30.439  &lt; 2e-16 ***
## hr17                       2.14049    0.05580  38.360  &lt; 2e-16 ***
## hr18                       2.03774    0.05595  36.419  &lt; 2e-16 ***
## hr19                       1.71154    0.05699  30.032  &lt; 2e-16 ***
## hr20                       1.39390    0.05848  23.834  &lt; 2e-16 ***
## hr21                       1.13254    0.06004  18.863  &lt; 2e-16 ***
## hr22                       0.88253    0.06214  14.203  &lt; 2e-16 ***
## hr23                       0.48135    0.06650   7.238 4.94e-13 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for quasipoisson family taken to be 42.44818)
## 
##     Null deviance: 1052921  on 8644  degrees of freedom
## Residual deviance:  375265  on 8615  degrees of freedom
## AIC: NA
## 
## Number of Fisher Scoring iterations: 5</code></pre>
</div>
</div>
</div>
<div id="a-final-note" class="section level1">
<h1><span class="header-section-number">3</span> A final note</h1>
<p>In this lecture, we have introduced GLMs to model data that can be assumed to follow a distribution belonging to the exponential family. We focussed on estimation, interpretation, statistical inference and some model goodness-of-fit diagnostics. We did not consider important topics like model selection, or even whether a GLM is appropriate for your dataset! These are other important topics which, unfortunately, we do not have the bandwidth for to include in this course. Therefore, a final note through an <a href="https://xkcd.com/">XKCD comic</a>, after finishing this long chapter!</p>
<p><img src="images_sequencing/xkcd-1725-linear_regression_2x.png" width="480" /></p>
</div>
<div id="references" class="section level1">
<h1><span class="header-section-number">4</span> References</h1>
<ul>
<li><a href="https://genome.cshlp.org/content/18/9/1509">Marioni <em>et al.</em> (2008)</a> describe the distribution of gene expression counts across technical replicates, and in addition discuss lane effects in RNA-seq, as well as a comparison between RNA-seq and array-based platforms.</li>
<li><a href="https://www.jstor.org/stable/2334725?seq=1#metadata_info_tab_contents">Wedderburn (1974)</a> introduced the (extended) quasi-likelihood framework.</li>
<li>The count data chapter of Modern Statistics for Modern Biology by Wolfgang Huber and Susan Holmes handles similar topics also in the context of RNA-seq: <a href="https://www.huber.embl.de/msmb/Chap-CountData.html" class="uri">https://www.huber.embl.de/msmb/Chap-CountData.html</a></li>
</ul>
</div>

<div id="rmd-source-code">---
title: 'Sequencing: Working with count data'
author: "Koen Van den Berge"
date: "Last edited on `r format(Sys.time(), '%d %B, %Y')`"
output: 
  pdf_document:
    toc: true
    number_sections: true
    latex_engine: xelatex
  html_document:
    toc: true
    toc_float: true
    toc_depth: 4
---

```{r functions, include=FALSE}
# A function for captioning and referencing images
fig <- local({
    i <- 0
    ref <- list()
    list(
        cap=function(refName, text) {
            i <<- i + 1
            ref[[refName]] <<- i
            paste("Figure ", i, ": ", text, sep="")
        },
        ref=function(refName) {
            ref[[refName]]
        })
})
``` 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
suppressPackageStartupMessages({
  library(knitr)
  library(rmarkdown)
  library(ggplot2)
})
```

In this lecture we will introduce the main principles of working with count data, and how to model these using generalized linear models (GLMs). We focus on introducing the concept of generalized linear models, and how to interpret its results. We touch briefly upon statistical inference, providing the main results rather than the theory behind it, such that they can be applied to genomics data analysis.

# The Poisson distribution

 - The Poisson distribution is a typical count distribution that is generally popular and fairly easy to work with. It is defined by a single parameter: its mean $\mu$. For a Poisson distributed random variable $Y_i$ with observations $i \in \{1, \ldots, n\}$, its variance is equal to its mean. That is, if $Y_i \sim Poi(\mu)$, then $E(Y_i) = Var(Y_i) = \mu$.
 - This immediately shows an important feature of count data: the **mean-variance relationship**. Indeed, in count data, the variance will always be a function of the mean.
 - This is quite intuitive. Consider the following example. You have two bird cages, where in one bird cage there are $10$ birds, while in the other there are $100$ birds. You let a sample of people count the number of birds in either one of the cages. It seems unlikely that a person in front of the 10-bird cage would come up with an estimate of $5$, while it seems quite likely that someone in front of the 100-bird cage would come up with an estimate of $95$. Even though the difference from the true value is the same, the exact value has an impact on the plausible deviation around it.
 
```{r}
set.seed(11)
y1 <- rpois(n=500, lambda=10)
y2 <- rpois(n=500, lambda=100)

par(mfrow = c(1,2))
hist(y1, main="Poisson(10)", breaks=40)
hist(y2, main="Poisson(100)", breaks=40)
```

## The Poisson distribution in RNA-seq

 - In RNA-seq, technical replicates represent different aliquots of the same sample being sequenced repeatedly. The underlying true expression of a gene can hence safely be assumed to be equal across these technical replicates.
 - [Marioni *et al.* (2008)](https://genome.cshlp.org/content/18/9/1509) have shown that, for most genes, the distribution of observed gene expression counts across technical replicates follow a Poisson distribution. A small proportion of genes ($\sim 0.5\%$) do not follow this Poisson model, however, and actually show evidence for *'extra-Poisson variation'*.
 
```{r, echo=FALSE, fig.cap=paste("Figure: Technical replication in RNA-seq. Figures from Marioni et al. (2008).")}
# All defaults
include_graphics("./images_sequencing/marioniFigs_cropped.png")
```

## Relative uncertainty for Poisson distributed random variables

Take a minute to consider the following question:

 - Suppose that we have a solid tumor sample from a cancer patient, as well as a sample of surrounding healthy tissue. For each sample, we have three technical replicates at our disposal. Let $Y_{grt}$ denote the observed gene expression values of gene $g$ in replicate $r \in \{1,2,3\}$ from tissue $t \in \{0,1\}$, where $t=0$ denotes healthy tissue and $t=1$ denotes tumoral tissue. 
 - We then know that the random variables $Y_{gr0}$ and $Y_{gr1}$ follow a Poisson distribution, and we would estimate its mean as $\bar{Y}_{g0} = \frac{1}{3} \sum_{r=1}^3 Y_{gr0}$ and $\bar{Y}_{g1} = \frac{1}{3} \sum_{r=1}^3 Y_{gr1}$, respectively. 
 - Similar, for another gene $k$, we observe $Y_{krt}$, and estimate $\bar{Y}_{k0}$ and $\bar{Y}_{k1}$ correspondingly.
 - Now suppose that $\beta_{k} = \bar{Y}_{k1} / \bar{Y}_{k0} = 5$, but also $\beta_g = \bar{Y}_{g1} / \bar{Y}_{g0} = 5$, i.e., the two genes have the same average expression ratio (also often called a fold-change) across samples. However, they are differently expressed as $\bar{Y}_{k1} = 100$, and $\bar{Y}_{g1} = 10$ (making $\bar{Y}_{k0} = 20$, and $\bar{Y}_{g0} = 2$).
 - For which of the two genes is the uncertainty on the expression ratio the highest? In other words, do we trust $\beta_k$ more or do we trust $\beta_g$ more?
 
 ---

Let's approximate the uncertainty in $beta_g$ and $\beta_k$ using simulation:
 
```{r}
N <- 1e3
beta_g <- beta_k <- vector(length=N)
for(ii in 1:N){
  ygr1 <- rpois(n=3, lambda=10)
  ygr0 <- rpois(n=3, lambda=2)
  ykr1 <- rpois(n=3, lambda=100)
  ykr0 <- rpois(n=3, lambda=20)
  beta_g[ii] <- mean(ygr1) / mean(ygr0)
  beta_k[ii] <- mean(ykr1) / mean(ykr0)
}

par(mfrow=c(1,2), mar=c(4,2,3,1))
hist(beta_g, breaks=seq(0,50,by=1), xlim=c(0,50))
hist(beta_k, breaks=seq(0,50,by=1), xlim=c(0,50))
```
 
 --- 
 
 We clearly see that the uncertainty on $\beta_k$ is much lower than on $\beta_g$. Even though the variance on the counts of gene $k$ is higher, since its mean is higher and it is distributed as a Poisson variable. How do we explain this?
 
 - We may explain this by considering the relative uncertainty on the mean. Relative uncertainty may be defined as the coefficient of variation $CV = \frac{\sigma}{\mu}$ (this is, the standard deviation divided by the mean). Indeed, the CV describes the relative deviation of the distribution relative to its mean, where a low CV indicates low dispersion with respect to the mean.
 - Calculating the CV shows that **the relative uncertainty for gene $k$ than for gene $g$, even though the variance on the raw counts is higher for gene $k$ than for gene $g$**. 
 - This lower relative uncertainty on the mean then propagates further to a lower uncertainty on the fold-change. This basic result will be essential for understanding the results of a differential expression analysis!
 
```{r}
sqrt(100)/100 #CV for gene k

sqrt(10)/10 #CV for gene g
```
 
# Modeling count data: Generalized linear models

Just like we have modeled protein abundances in the proteomics module of this course in order to assess differential protein abundance, we can model gene expression counts to identify genes with differences in average expression between groups of samples.

## Why we can('t) use linear models to model count data

 - If we're using a linear model to model a response $Y_i$, with $i \in \{1, \ldots, n\}$ in function of a single covariate $X_i$, the linear model can be defined as follows:

\[
\left\{
\begin{array}{ccc}
Y_i & = & \beta_0 + \beta_1 X_i + \epsilon_i \\
Y_i | X_i & \sim & N(\beta_0 + \beta_1 X_i, \sigma^2 \mathbf{I}).
\end{array}
\right.
\]

 - Or, equivalently, we've seen we can write it in matrix form as
  $$
  \left\{
  \begin{array}{ccc}
  Y_i & = & \mathbf{X}^T_i \beta + \epsilon_i \\
  Y_i | \mathbf{X}_i & \sim & N(\mathbf{X}^T_i \beta, \sigma^2 \mathbf{I}),
  \end{array}
  \right.
  $$
where $\mathbf{X}$ now represents our $n \times p$ design matrix, with row $i$ corresponding to observation $i$.

 ---

 - The variance-covariance matrix of $\mathbf{Y}$ is assumed a diagonal matrix with $\sigma^2$ on the diagonal elements and zero everywhere else. This means that the data points are uncorrelated, and that every observation has the same variance $\sigma^2$, also referred to as homoscedasticity. 
 - The latter doesn't hold for count data, due to the mean-variance relationship. This makes linear models, in its basic form, unsuitable to model count data.
 - In addition, count data are non-negative, while there are no such constraints in the standard linear model to make sure that our estimates will be non-negative. Indeed, $\hat{Y}_i = \mathbf{X}^T_i \hat{\beta} \in ] -\infty, \infty[$.

## Generalized linear models

 - As the name suggests, generalized linear models (GLMs) extend linear models. In GLMs, we extend two things with respect to the linear model:
    - The **conditional distribution of the response variable $Y_i | X_i$** can be assumed to follow any distribution that belongs to the **exponential family** of distributions, which includes the Gaussian but also other commonly known distributions, such as the Binomial, Gamma and Poisson distribution.
    - The linear model assumed a linear relationship between $Y_i$ and $X_i$, since we assumed that $E(Y_i | X_i) = \mathbf{X}^T_i \beta$. In GLMs, we will allow a **link function** $g()$ that links the conditional mean to the covariates. Hence, in GLMs we have that $g(E(Y_i | X_i)) = \mathbf{X}^T_i \beta$. Note that each family has got a canonical link function, which is the identity link function $g(\mu) = \mu$ for Gaussian, the log link function $g(\mu) = \log \mu$ for Poisson, or the logit link function $g(\mu) = \log(\frac{\mu}{1-\mu})$ for Binomial.
    
### A Poisson GLM

 - We can define a Poisson GLM as follows
  $$
  \left\{
  \begin{array}{ccc}
  Y_i & \sim & Poi(\mu_i) \\
  \log \mu_i & = & \eta_i \\
  \eta_i & = & \mathbf{X}^T_i \beta \\
  \end{array}
  \right.
  $$
where $Y_i$ is the response variable, with mean $\mu_i$, $\eta_i$ is the linear predictor, $\mathbf{X}$ is the $n \times p$ model matrix and $\beta$ is the $p \times 1$ matrix of regression coefficients.
  - It is insightful to compare this model to a linear model where $Y_i$ is log-transformed. Indeed, in the linear model case, we would be modeling $E(\log Y_i )$, while in the GLM we are modeling $\log E(Y_i)$.
  - This shows that in the GLM setting we are modeling a transformed version of the expected value, and after retransforming we can interpret the fit in terms of the mean of our response variable. In the transformed linear model, however, we are working with the expected value of a transformed version of our response variable, and we will not be able to interpret the fit in terms of the mean (because $E( \log Y_i) \ne \log E(Y_i)$. In this specific case, we would have to resort to interpreting changes in terms of a geometric mean.
  - Also note that $\mathbf{X}^T_i \beta \in ]-\infty, \infty[$, while $Y_i$ must be non-negative $[0, \infty[$. The link function helps with this, since the exponential function transforms any real number to a non-negative number, i.e., $\exp(\mathbf{X}^T_i \beta) \in [0, \infty[$. 
  

### Parameter estimation using maximum likelihood

 - In maximum likelihood, we attempt to **maximize the likelihood function of the data**, under the posited assumptions. The likelihood function is typically parametrized by a limited number of parameters, hence we can find the values of the parameters that maximize the likelihood function.
 - We do this by finding the point on the likelihood function where its first derivative equals zero, as this must be a maximum of the function. For non-convex likelihood functions, this may be a local maximum, but for GLMs the likelihood function is convex and therefore the obtained maximum must be the global maximum.
 
#### Maximum likelihood for a linear model

For linear models, we can derive an equivalent estimator for $\beta$ using maximum likelihood estimation as we had derived in our recap lecture using least squares estimation. We can define a linear model as

$$
Y_i \sim N(\mu_i, \sigma^2\mathbf{I}) \\
\mu_i = \mathbf{X}_i \mathbf{\beta}
$$
 
The likelihood function of the data is the product of the likelihoods of each datum. Since we are assuming a Gaussian distribution, we use the Gaussian probability density function:

$$
L(\mathbf{Y}; \beta, \sigma) = \prod_{i=1}^n \frac{1}{\sqrt{2 \pi \sigma^2}} \exp \left\{ - \frac{(Y_i - \mathbf{X}_i \beta)^2}{2 \sigma^2} \right\}
$$
 
Log-likelihood function

$$
\ell(\mathbf{Y}; \beta, \sigma) = \sum_{i=1}^n \left\{ -\frac{1}{2} \log(2\pi \sigma^2) - \frac{1}{2\sigma^2} (Y_i - \mathbf{X}_i \beta)^2 \right\}
$$
 
Score function is the derivative of the log-likelihood

$$
S(\mathbf{\beta}) = \frac{\partial \ell(\mathbf{Y}; \beta, \sigma)}{\partial \beta} = \sum_{i=1}^n \frac{1}{\sigma^2} \mathbf{X}_i (Y_i - \mathbf{X}_i \beta)
$$
 
 Set to zero and solve
 
$$
\mathbf{X}^T\mathbf{Y} - \mathbf{X}^T \mathbf{X} \mathbf{\beta} = \mathbf{0} \\
\rightarrow \widehat{\mathbf{\beta}} = (\mathbf{X}^T \mathbf{X})^{-1} \mathbf{X}^T\mathbf{Y}
$$
 
which gives us exactly the same estimator as we had derived using least squares!

#### Maximum likelihood for a generalized linear model

Now that we know how to use maximum likelihood for parameter estimation, we can also apply it to estimate the parameters of a generalized linear model. Let's try it for the Poisson GLM we have just introduced:

$$
\left\{
\begin{array}{ccc}
Y_i & \sim & Poi(\mu_i) \\
\log \mu_i & = & \eta_i \\
\eta_i & = & \mathbf{X}^T_i \beta \\
\end{array}
\right.
$$


Likelihood function of the Poisson distribution

$$
L(Y_i ; \mu) = \prod_{i=1}^n \frac{e^{-\mu} \mu^{Y_i}}{Y_i!}
$$

Log-likelihood function

$$
\ell(Y_i ; \mu) = \sum_{i=1}^n - \mu + Y_i \log(\mu) - \log (Y_i!)
$$

Note that the score function is the derivative of the log-likelihood with respect to our parameter of interest, $\beta$. So let's first rewrite our log-likelihood as a function of our parameter of interest. We know from the model that $\mu_i = \exp(\mathbf{X}_i \mathbf{\beta})$.

$$
\ell(Y_i ; \beta) = \sum_{i=1}^n - \exp(\mathbf{X}_i \mathbf{\beta}) + Y_i (\mathbf{X}_i \mathbf{\beta}) - \log (Y_i!)
$$

The score function then equals

$$
S(\mathbf{\beta}) = \frac{\partial \ell(\mathbf{Y}; \beta)}{\partial \beta} = \sum_{i=1}^n -\mathbf{X}_i^T \exp(\mathbf{X}_i \mathbf{\beta}) + \mathbf{X}_i^TY_i = -\mathbf{X}^T \exp(\mathbf{X} \mathbf{\beta}) + \mathbf{X}^T \mathbf{Y}
$$

Set to zero and solve

$$
\mathbf{X}^T \mathbf{Y} = \mathbf{X}^T \exp(\mathbf{X} \mathbf{\beta})
$$

However, since this is a non-linear equation in $\beta$, we cannot find a closed-form solution! You may see this more clearly when writing out in non-matrix form

$$
\sum_i \sum_p x_{ip} \exp(x_{ip} \beta_p) = \sum_i \sum_p x_{ip} Y_i.
$$

 ---

 - The above derivations show that estimating the parameters of a GLM is much harder as compared to a linear model.
 - The **iterative reweighted least squares (IRLS)** algorithm is usually adopted for fitting GLMs using maximum likelihood. As the name suggests, it is an iterative algorithm, where each data point is reweighted in each iteration according to the assumed mean-variance relationship, which is a function of its estimated mean of the previous iteration. Indeed, observations with high variance will be downweighted and vice versa. IRLS uses the derivative of the score function (i.e., the second derivative of the log-likelihood function) to move into the direction where the first derivative is zero.
 
```{r, echo=FALSE, fig.cap=paste("")}
# All defaults
include_graphics("./images_sequencing/irlsScheme.png")
```
Figure: Finding the root of the score function using Newton-Raphson optimization. The Figure shows estimation of a single $\beta$ parameter. The black solid line is the Score function evaluated at $\beta$. An initial estimate of $\beta$ is 2.25, which is represented by the dotted line. The value of the score function of this initial value is $S(\beta^k)$. The first derivative of the score function at that point, evaluated at $\beta = 2.25$, is represented by the solid blue line and is given by $\frac{\partial S(\beta)}{\partial \beta}$. The value of $\beta$ where the solid blue line crosses zero is the new estimate for $\beta$, namely $\beta^{k+1}$ which has a value of 1.4. The difference between $\beta^{k+1}$ and $\beta^{k}$ is given by $\left \{ \frac{ \partial S(\beta)}{ \partial \beta}   \right \}^{-1} S(\beta^k)$. This procedure is iterated until a convergence in the $\beta$ estimate is met.

### Generalized linear models in `R`

 - In order to get familiar with GLMs, we will fit a Poisson GLM in `R`, using the `Bikeshare` dataset as part of the `ISLR2` package. This dataset records how many bikes were being used from a bike-sharing service, every hour of the day over a full year (365 days).
 - Full information of the dataset is provided [here](https://archive.ics.uci.edu/ml/datasets/bike+sharing+dataset). Variables of interest for us are:
 
    - `bikers`: Discrete count variable; the number of bikes being used that hour.
    - `hum`: Continuous variable ranging between 0 and 1; normalized humidity.
    - `hr`: Categorical variable between 0 and 23; the hour of the day. One could also consider this variable to be numeric and model it as such, but the data exploration will show that's not appropriate.
    - `weathersit`: Categorical variable; the weather condition of that hour, with
    
      1. Clear, Few clouds, Partly cloudy.
      2. Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist.
      3. Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds.
      4. Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog.
    
 ---  

```{r}
# if ISLR2 isn't installed, install it:
if(!"ISLR2" %in% installed.packages()[,1]){
  install.packages("ISLR2")
}
# load and preview the dataset:
data("Bikeshare", package="ISLR2")
head(Bikeshare)

# association with weather on count and log scale
barplot(table(Bikeshare$weathersit))
boxplot(bikers ~ weathersit, data=Bikeshare,
        xlab = "Weather", ylab = "Bikers")
boxplot(log1p(bikers) ~ weathersit, data=Bikeshare,
        xlab = "Weather", ylab = "Log (bikers +1)")

# association with humidity on count and log scale
hist(Bikeshare$hum, breaks=40)
plot(bikers ~ hum, data=Bikeshare, pch=16, cex=1/2,
        xlab = "Humidity", ylab = "Bikers")
loHum <- loess(bikers ~ hum, data=Bikeshare)
xGrid <- seq(0, 1, length=50)
yhat <- predict(loHum, data.frame(hum = xGrid))
lines(x=xGrid, y=yhat, col="red", lwd=3)

plot(log1p(bikers) ~ hum, data=Bikeshare, pch=16, cex=1/2,
        xlab = "Humidity", ylab = "Log (bikers +1)")
loHum <- loess(log1p(bikers) ~ hum, data=Bikeshare)
xGrid <- seq(0, 1, length=50)
yhat <- predict(loHum, data.frame(hum = xGrid))
lines(x=xGrid, y=yhat, col="red", lwd=3)

# association with hour on count and log scale
barplot(table(Bikeshare$hr), xlab="Hour of day", ylab="Number of observations")
plot(bikers ~ hr, data=Bikeshare, pch=16, cex=1/2,
        xlab = "Hour of day", ylab = "Bikers")
plot(log1p(bikers) ~ hr, data=Bikeshare, pch=16, cex=1/2,
        xlab = "Hour of day", ylab = "Log (bikers +1)")
```

The data exploration shows that

 - More bikes are being used in better weather.
 - There seems to be a non-linear association between bicycle rentals and humidity, where in both low and high humidity conditions relatively few bikes are used, possibly reflecting very hot and very wet days respectively, while most bikes are being used at moderate humidity.
 - Bicycle rental is associated with the hour of the day, however, in a non-linear way, with clear peaks in usage at typical commute hours (6h-8h and 17h-19h). Here, we will add `hr` as a categorical variable to the model, estimating one parameter for each hour. Note that alternative strategies are possible that may be more efficient, such as incorporating `hr` as a numerical variable and modeling the non-linearity using a lower number of parameters.
 - *Disclaimer*: Note that there are likely interactions between the variables, which here we will not evaluate as our goal is to introduce a Poisson GLM rather than a full analysis of the `Bikeshare` dataset. For example, it seems likely that more people commute by bike in good weather, while fewer people will commute by bike in terrible weather. This would motivate an interaction between the variables `weathersit` and `hr`.
 
 ---
 
 - Below, we fit a Poisson GLM using the `glm` function. The number of bikers is used as a response variable, which is modeled as a function of `weathersit`, `hum` and `hr`. 
 - Note that there seems to be a non-linear, though fairly simple, association between our response variable and the humidity. We will therefore add a quadratic and cubic term for humidity to the model. In order to avoid multicollinearity between the linear, quadratic and cubic humidity effects, we will first center the humidity variable and store this in a new variable called `humc`. This means that when `humc=0`, this corresponds to the average humidity in the dataset.
 - The argument `family = "poisson"` specifies the Poisson distribution for the response variable and by default the canonical link function, which is the log link, will be used.
 
```{r}
Bikeshare$humc <- Bikeshare$hum - mean(Bikeshare$hum)
m <- glm(bikers ~ weathersit + humc + I(humc^2) + I(humc^3) + hr,
         data = Bikeshare,
         family = "poisson")
summary(m)
```

#### Interpretation of estimated model parameters 

 - Remember that the Poisson GLM can be defined as
 $$
  \left\{
  \begin{array}{ccc}
  Y_i & \sim & Poi(\mu_i) \\
  \log \mu_i & = & \eta_i \\
  \eta_i & = & \mathbf{X}^T_i \beta \\
  \end{array}
  \right.
  $$
  
 *Interpretation of the intercept.*
  
 - We will first interpret the intercept, in terms of the average number of bikes being used. Note that the intercept corresponds to hour 0, at good weather (`weathersit` level 1), and average humidity (`humc`=0). We will denote the intercept as $\beta_0$ and its estimate as $\hat{\beta}_0$. All other coefficients will thus denote a relative change with respect to that reference level.
 - The model definition shows that $\log \mu_i = \mathbf{X}^T_i \mathbf{\beta}$, with $\mu$ the average number of bikes being used. Since we're only working with the intercept here, we may write $\log \mu_i = \beta_0$, and thus $\mu_i = \exp \beta_0$.
 - Plugging in the estimated intercept $\hat{\beta}_0$, we have $\exp \hat{\beta}_0 =$ `r round(exp(coef(m)[1]), 2)`. In other words, in clear weather with few clouds, at zero humidity and at hour 0, an average of `r round(exp(coef(m)[1]), 2)` bikes are being used.
 
 ---
 
 *Interpretation of `weathersitcloudy/misty`.*
 
 - We will denote this coefficient as $\beta_1$ and its estimate as $\hat{\beta}_1$. 
 - Note that this coefficient defines the difference in linear predictor between `weathersit=2` and `weathersit=1`, all other variables being equal (say, at their reference level). Indeed, define $\eta_{w2}$ and $\eta_{w1}$ to denote the linear predictor at `weathersit=2`, and `weathersit=1`, respectively. Then, $\eta_{w2} - \eta_{w1} = (\beta_0 + \beta_1) - \beta_0 = \beta_1$.
 - This also means that $\beta_1 = \log \mu_{w2} - \log \mu_{w1} = \log \frac{\mu_{w2}}{\mu_{21}}$, and thus $\exp \beta_1 = \frac{\mu_{w2}}{\mu_{21}}$.
 - In our case, $\exp \hat{\beta}_1 =$ `r round(exp(coef(m)[2]), 2)`. In words: All other variables being equal, the average number of bikes being used in cloudy/misty weather is $0.85$ times (or, also, $85\%$ of) the number of bikes being used in good weather.
 - This exercise has shown us that, **due to the $\log$ link function**, the parameters in a Poisson GLM cannot be interpreted in terms of absolute differences in averages of the response variable but instead must be interpreted in terms of **multiplicative differences**!
 - If you're in a meeting and you need a quick way to interpret these parameters, remember that $exp(1) = 2.72 \approx 3$ and thus a difference of $1$ ($-1$) means the average of the response variable is about three times higher (lower).
 
 ---
 
 *Interpretation of the humidity effect.*
 
 - The humidity effect is a bit more involved to interpret. Due to the quadratic and cubic terms, we cannot interpret the linear term separately (nor can we interpret the quadratic or cubic term separately); we must interpret both the linear, quadratic and cubic term simultaneously.
 - Also due to the higher-order terms, the rate of change in average bikers will not be constant across the range of humidity. We can therefore not interpret the humidity effect using a single number as we've done previously.
 - We can, however, provide some examples for specific humidity values, along with a visualization of its global effect.
  - For example, let's derive the change in average bikes being used at a humidity that is $0.2$ above average, versus average humidity.
  
    For average humidity $+0.2$ the linear predictor $\eta_{0.2} = \beta_0 + \beta_4 x_{hum} + \beta_5 x_{hum}^2 + \beta_6 x_{hum}^3 = \beta_0 + \beta_4 0.2 + \beta_5 0.2^2 + \beta_6 0.2^3$.
    
    For average humidity, the linear predictor $\eta_{0} = \beta_0 + \beta_4 x_{hum} + \beta_5 x_{hum}^2 + \beta_6 x_{hum}^3 = \beta_0 + \beta_4 0 + \beta_5 0^2 + \beta_6 0^3 = \beta_0$.
    
    We thus have $\log \frac{\mu_{0.2}}{\mu_0} = \beta_4 0.2 + \beta_5 0.2^2 + \beta_6 0.2^3$. In our case, $\log \frac{\hat{\mu}_{0.2}}{\hat{\mu}_0} = 0.091751*0.2 - 2.233919 * 0.2^2 - 1.823066 * 0.2^3 = -0.0856$ and thus $\frac{\hat{\mu}_{0.2}}{\hat{\mu}_0} = 0.92$. Therefore, at humidity that is $0.2$ above average, the average number of bikes being used are $0.92$ times the average number of bikes used at average humidity.
 - Just like with linear models, the `predict` function is extremely helpful when trying to visualize and understand a fitted GLM. In GLMs, the `type` argument becomes essential when using the `predict` function. Indeed, by default, estimates are provided on the linear predictor scale: in our case, on the $\log$ scale. If we'd like predictions on the scale of the response variable, we need to set `type="response"`. You can find more information in the help file using `?predict.glm`.
 - The visualization shows that the highest number of bikes are being used at around average humidity, with a decreased usage at higher and lower humidities.
 
```{r}
humidityGrid <- seq(min(Bikeshare$humc), max(Bikeshare$humc), 
                    length.out = 50)
newDf <- data.frame(weathersit = factor("clear"),
                    hr = factor(8),
                    humc = humidityGrid,
                    "I(humc^2)" = humidityGrid^2,
                    "I(humc^3)" = humidityGrid^3)
yhat <- predict(m, 
                newdata = newDf,
                type = "response")

plot(x = humidityGrid,
     y = yhat,
     type = 'l', lwd=2,
     xlab = "Centered humidity",
     ylab = "Average number of bikers")

```
 
 --- 
 
 *Setting up a contrast.*
 
 - Suppose we're interested in whether there are more bikers at (A) maximum humidity (centered humidity value of $0.357$), hour 17, in the `light rain/snow` weather category, versus (B) average humidity, hour 8, in the `clear` weather category. This requires us to set up a contrast in terms of a linear combination of the model parameters.
 - **Manually by hand**: 
 $$ \log \mu_A = \beta_0 + \beta_2 x_{rainSnow} + \beta_4 x_{hum} + \beta_5 x_{hum}^2 + \beta_6 x_{hum}^3 + \beta_{23} x_{hr17} \\= 3.894 - 0.556 + 0.092 * 0.357 - 2.234 * 0.357^2 - 1.823 * 0.357^3 + 2.140 = 5.143.\\
   \log \mu_B = \beta_0 + \beta_{14} x_{hr8} = 3.894 + 1.830 = 5.724.\\
   \frac{\mu_A}{\mu_B} = \exp(5.143 - 5.724) = 0.559.
   $$
   Thus, at maximum humidity, hour 17, in the `light rain/snow` weather category the average number of bikers is 56% times the average number of bikers in the average humidity, hour 8, in the `clear` weather category.
 - **Manually in `R`**: We can also use matrix multiplication to derive the estimates. We know from our manual calculations above, that the contrast of interest is $(\beta_0 + \beta_2 x_{rainSnow} + \beta_4 x_{hum} + \beta_5 x_{hum}^+ \beta_6 x_{hum}^3 + \beta_{23} x_{hr17}) - (\beta_0 + \beta_{14} x_{hr8})$. We can store this in a contrast matrix, and then multiply it with the coefficients of our model:
 
```{r}
L <- matrix(0, 
            nrow = length(coef(m)),
            ncol = 1)
rownames(L) <- names(coef(m))
L["weathersitlight rain/snow",1] <- 1
L["humc",1] <- 0.357
L["I(humc^2)", 1] <- 0.357^2
L["I(humc^3)", 1] <- 0.357^3
L["hr17", 1] <- 1
L["hr8",1] <- -1
L

beta <- matrix(coef(m), ncol=1)
exp(t(L) %*% beta) # equals our manual calculation.
```
   
 - **Using `predict` in `R`**:

```{r}
# set up data frames with relevant predictor variables' values.
dfA <- data.frame(weathersit = factor("light rain/snow"),
                    hr = factor(17),
                    humc = 0.357,
                    "I(humc^2)" = 0.357^2,
                    "I(humc^3)" = 0.357^3)
dfB <- data.frame(weathersit = factor("clear"),
                    hr = factor(8),
                    humc = 0,
                    "I(humc^2)" = 0,
                    "I(humc^3)" = 0)

# calculate estimated average number of bikers
yhatA <- predict(m, 
                newdata = dfA,
                type = "response")
yhatB <- predict(m, 
                newdata = dfB,
                type = "response")

yhatA / yhatB # also equal to above.
```
 
 ---
 
 **Exercise**: try to derive the change in average number of bikers between (a) humidity of 0.1 above average, clear weather (`weathersit=1`), at hour 10 and (b) humidity of 0.1 below average, cloudy weather (`weathersit=2`), at hour 20, using all three methods.
 
## Statistical inference in GLMs

### Wald test and likelihood ratio test

 - In our interpretation above we have focussed on deriving changes in the average number of bikers between groups of interest. However, we have not yet tested whether these changes are statistically significant.
 - In genomics applications, statistical inference in GLMs is often adopted to test for differential expression between conditions for each gene (e.g., *is gene A differently expressed in healthy versus tumoral tissue?*), which amounts to testing the null hypothesis of whether a (linear combination of) coefficient(s) equals zero.
 - In this course, we will mainly work with two types of statistical tests for GLMs:
   - **Wald test**: The Wald test may be viewed as being anaologous to the $t$-test we are using in linear models. The Wald test relies on the following asymptotic result
   $$\hat{\beta} | \beta \sim N (\beta, Var(\hat{\beta}))$$.
   The Wald test statistic for testing a single parameter $\hat{\beta}$
   $$W = \frac{\hat{\beta}}{\hat{SE}(\hat{\beta})} \sim N(0,1) | H_0$$
   or, equivalently, letting $\mathbf{C}$ denote the $1 \times p$ contrast matrix denoting the contrast for the single parameter $\beta$ we would like to test, and $\hat{\Sigma}_{\hat{\beta}}$  the $p \times p$ variance-covariance matrix of the parameters,
   $$W = \mathbf{C}\hat{\beta} (\mathbf{C} \hat{\Sigma}_{\hat{\beta}} \mathbf{C}^T)^{-1} \hat{\beta}^T \mathbf{C}^T \sim \chi^2_1 | H_0.$$
   The null and alternative hypothesis can therefore in general be written as
   $$ H_0: \mathbf{C}\hat{\beta} = 0$$
   $$ H_1: \mathbf{C}\hat{\beta} \ne 0$$
   If $c \ge 1$ contrasts are tested, then the test statistic $W \sim \chi^2_c | H_0$, provided that the $c$ contrasts are linearly independent (i.e., the contrast matrix is full rank).
   - **Likelihood ratio test**: The likelihood ratio test (LRT) measures the discrepancy in log-likelihood between our current model (sometimes also referred to as full model) and a reduced model (sometimes also referred to as null or alternative model). The reduced model must be nested in (and therefore of lower dimension as compared to) the full model. While adding more covariates will always explain more variability in our response variable, the LRT tests whether this is actually significant.
   For example, in the example of gene differential expression between healthy versus tumoral tissue, the full model could be a GLM where the mean is modeled according to an intercept and a tissue indicator variable (healthy / tumoral), while the alternative model could be a GLM with just an intercept. Indeed, if the gene is similarly expressed between healthy and tumoral tissue, the log-likelihood of the alternative model will decrease only a little as compared to the full model.
   As the name suggests, the likelihood ratio test assesses whether the ratio of the log-likelihoods provides sufficient evidence for a worse fit of the alternative versus full model
   $$L = 2 \log \left\{ \ell(\hat{\beta}_{full}) -  \ell(\hat{\beta}_{alternative}) \right\}.$$
   Asymptotically, under the null hypothesis it can be shown that
   $$ L \sim \chi_c^2 | H_0, $$
   with $c$ the number of parameters dropped in the alternative model versus the full model. If we again let $\mathbf{C}$ denote the $c \times p$ contrast matrix denoting the contrast for the parameters being dropped, the null and alternative hypothesis are as in the Wald test setting:
   $$ H_0: \mathbf{C}\hat{\beta} = 0$$
   $$ H_1: \mathbf{C}\hat{\beta} \ne 0$$
   Finally, note that while, in this explanation, I have focussed on reducing a more complex model, but of course the LRT can also be adopted to check whether adding a covariate significantly improves the fit.
 - It is important to keep in mind that standard statistical inference theory in GLMs works **asymptotically in terms of the sample size**. Thus we need many data points in order for the theory to hold in practice. In order for the $p$-values to be correct, our parametric (distributional) assumptions as well as the independence assumption, must also hold.
 - In bulk RNA-seq, we are often working with a limited number of samples and so we typically do not expect asymptotic theory to hold yet. In single-cell RNA-seq, we often perform several preprocessing steps before calculating $p$-values for each gene and so we may be 'using the data multiple times'. Rather than attaching strong probabilistic interpretations to the $p$-values, we therefore advice to view the $p$-values simply as useful numerical summaries for ranking the genes for further inspection in genomics applications.
 
 **TODO: add schematic comparing Wald with LRT using log-likelihood function**
  
### Wald test and likelihood ratio test in `R`

Let's use a Wald test and a likelihood ratio test to test whether the average number of bikers differs between a working day or a weekend day, using a simple GLM with only that variable as a covariate.
This amounts to testing

$$H_0: \beta_{workingday} = 0$$
$$H_1: \beta_{workingday} \ne 0$$

```{r waldTest}
mSimple <- glm(bikers ~ workingday, 
               family = "poisson", 
               data = Bikeshare)
summSimple <- summary(mSimple)
summSimple$coefficients["workingday",]
# Wald test manually
W <- summSimple$coefficients["workingday", "Estimate"] / summSimple$coefficients["workingday", "Std. Error"]
pval <- 2*(1 - pnorm(W))
W
pval
 
# Wald test through a contrast
C <- matrix(0, nrow=1, ncol=length(coef(mSimple)))
colnames(C) <- names(coef(mSimple))
C[, "workingday"] <- 1
beta <- matrix(coef(mSimple), ncol=1)
Sigma <- vcov(mSimple)

W2 <- C %*% beta %*% solve(C %*% Sigma %*% t(C)) %*% t(beta) %*% t(C)
W2
# note this being equal to
W^2
pval <- 1-pchisq(W, df=1)
pval

# finally, we can also read the Wald test result from the summary of the model
summSimple
```

```{r lrTest}
mFull <- glm(bikers ~ workingday, 
               family = "poisson", 
               data = Bikeshare)

mReduced <- glm(bikers ~ 1, 
               family = "poisson", 
               data = Bikeshare)

# manual LRT
llFull <- logLik(mFull)
llReduced <- logLik(mReduced)

lrt <- as.numeric(2 * (llFull - llReduced))
lrt
pval <- 1 - pchisq(lrt, df=1)
pval

# using anova function
anova(mReduced, mFull, test = "Chisq") # note test statistic is identical
```
 
## Model deviance, residuals and goodness-of-fit

 - In linear models, we often use residuals $e_i = y_i - \hat{\mu}_i$ to check model assumptions (linearity, homoscedasticity). However, in a GLM setting, we know that the variance of our residuals will depend on the mean, i.e., $Var(\epsilon_i) = f(\mu_i)$. Using ordinary residuals such as $e_i$ therefore is no longer appropriate.
 - We have seen that the objective function that is used to fit a GLM is the log-likelihood of the data under the posited model. For example, the log likelihood of a Poisson GLM with response variable $\mathbf{Y}$, with elements $Y_i, i \in \{1, \ldots, n\}$ and model matrix $\mathbf{X}$ is
 $$ \ell(\mathbf{Y};  \beta) = \log \prod_{i=1}^n \left( \frac{\exp (\mathbf{X}_i^T \beta)^{Y_i} \exp( - \exp(\mathbf{X}_i^T \beta))}{Y_i!} \right) = \sum_{i=1}^n \log \left( \frac{\exp(\mathbf{X}_i^T \beta)^{Y_i} \exp( - \exp(\mathbf{X}_i^T \beta))}{Y_i!} \right) \\ = \sum_{i=1}^n Y_i (\mathbf{X}_i^T \beta) + \exp(\mathbf{X}_i^T \beta)  - \log Y_i!. $$
 The estimates $\hat{\beta}$ are then found by maximizing $\ell(\beta | \mathbf{Y}, \mathbf{X} )$ with respect to $\beta$. This is analogous to maximizing a Gaussian likelihood in the linear model setting.
 - A goodness-of-fit measure used in the GLM setting is the **residual deviance** $D$ (sometimes referred to simply as 'deviance'), that is twice the difference in log-likelihood between a 'saturated model' and the current model. Here, a saturated model, is a model where we fit one parameter per data point and therefore fit the data perfectly, in other words $\hat{\mu}_i = y_i$. This is,
 $$ D = 2 * \left\{ \ell(\mathbf{Y};  \beta | \hat{\mu}_i = y_i) - \ell(\mathbf{Y};  \beta | \hat{\mu}_i = \exp(\mathbf{X}_i^T \beta)) \right\}.$$
 - From the equation above it becomes clear that the residual deviance is actually a ratio in log-likelihoods and therefore a likelihood ratio test statistic!
 - A low residual deviance can thus be interpreted as a model that is fitting the data well, since your current model will be close in log-likelihood to the saturated model. The deviance is a very useful statistic that is also important in statistical inference and model selection, e.g., for testing if a smaller model fits significantly worse than a larger model.
 - Finally, a **deviance residual** $D_i$ can then be defined as the square root of the contribution of the $i$th datum to the residual deviance
 $$ D_i = \sqrt{ 2* \left\{ \ell(Y_i;  \beta | \hat{\mu}_i = y_i) - \ell(Y_i;  \beta | \hat{\mu}_i = \exp(\mathbf{X}_i^T \beta)) \right\} } $$
 
 ---
 
 - Another type of residuals commonly used in a GLM setting are **Pearson residuals**. A Pearson residual is defined as
 $$ e_i = \frac{y_i - \hat{\mu}_i}{\sqrt{Var(\hat{\mu}_i)}},$$
 and we can see that it has the form of a regular residual such as used in liner models (numerator), but normalized according to the variance of the estimated mean (denominator), to correct for the mean-variance relationship.
 
 ---
 
 - **Goodness-of-fit** (GOF) analyses serve to assess how well the model actually fits the observed data. One may view the fitting of a GLM as replacing a set of observed data points $\mathbf{y}$ by a set of fitted values $\hat{\mathbf{\mu}}$ derived from a model. In general $\hat{\mathbf{\mu}} \ne \mathbf{y}$ and the question arises as to how well $\hat{\mathbf{\mu}}$ approximates $\mathbf{y}$. This naturally raises the question of how much of a discrepancy we believe to be tolerable. Two important discrepancy measures are often used in a GLM setting. 
 - Note that the **residual deviance** was a likelihood ratio test statistic between a saturated and our current model. This saturated model actually provides us with a baseline as to how well a model can fit the observed data (even if we know that the saturated model is uninformative for summarizing the data). This motivates a statistical test with  
 $H_0$: The current model provides a similar fit as the saturated model.  
 $H_1$: The current model fits significantly worse than a saturated model.  
 - The residual deviance immediately tests this hypothesis using a likelihood ratio test and is therefore a useful goodness-of-fit measure.
 - Another measure of discrepancy is the generalized Pearson $\chi^2$ statistic
 $$ X^2 = \sum_{i=1}^n \frac{(y_i - \hat{\mu}_i)^2}{Var(\hat{\mu}_i)} = \sum_{i=1}^n e_i^2,$$
 with $e_i$ the Pearson residual of observation $i$. 
  - Asymptotic theory shows that both the residual deviance $D \sim \chi^2_{n-p} | H_0$ and $X^2 \sim \chi^2_{n-p} | H_0$, with $n$ the number of observations in our dataset (and, hence, the number of parameters fitted in our saturated model), and $p$ the number of parameters fitted in our current model.
 
 ---

 **Exercise**:
 
 - Verify the residual deviance that is reported in the summary of our model above. 
 - Also check if you can recover the correct deviance and Pearson residuals by calculating them yourself. You can get the correct deviance residuals in `R` by `resid(m, type="deviance")` and `resid(m, type="pearson")`.
 - Does your model fit significantly worse than a saturated model?

## Overdispersion

 - Above we have always assumed that the Poisson distribution is valid for the dataset we have been using. However, we never checked for this.
 - As a matter of fact, it often happens that the variance=mean assumption is too stringent for count data. If the variance is larger than the mean, this is referred to as **overdispersion**. Though much less common, underdispersion happens when the variance is smaller than the mean.
 - We can use Pearson residuals to measure overdispersion using the following argument. The Poisson GLM implies that
 $$ Y_i | X_i, \hat{\beta} \sim Poi(\hat{\mu}_i),$$
 with $\hat{\mu}_i = \exp (\mathbf{X}_i^T \hat{\beta})$. This implies
 $$ Var(Y_i | X, \hat{\beta}) = \hat{\mu}_i.$$
 Since the variance is unaffected by addition we may also write
 $$ Var(Y_i - \hat{\mu}_i | X, \hat{\beta}) = \hat{\mu}_i.$$
 Which is also equal to
 $$ Var\left(\frac{Y_i - \hat{\mu}_i}{\sqrt{Var(\hat{\mu}_i)}} | X, \hat{\beta} \right) = \frac{\hat{\mu}_i}{Var(\hat{\mu}_i)}.$$
 Since we know from the Poisson distribution that $Var(\hat{\mu}_i) = \hat{\mu}_i$, we have that 
 $$ Var \left(\frac{Y_i - \hat{\mu}_i}{\sqrt{\hat{\mu}_i}} | X, \hat{\beta} \right) = \frac{\hat{\mu}_i}{\hat{\mu}_i}.$$
 Note that the formulation within the variance at left-hand side of the equation is our definition of Pearson residuals $E_i$. Thus, if the Poisson assumption holds, we can write
 $$ Var(E_i | X, \hat{\beta}) = 1,$$
 which is something we can empirically test using our fitted model. Indeed, **if the variance of our Pearson residuals is much larger than $1$, we are dealing with overdispersion**. As a rough rule, I consider overdispersion to be present if this value is larger than $\sim 1.3$, but this is arbitrary and may depend on the situation (and statistician). 
 
 ---
 
 - Below, we apply this to the `Bikeshare` dataset. We will notice that the overdispersion is huge! The p-values and standard errors provided by the model can therefore not be trusted!

```{r}
ePearson <- resid(m, type="pearson")
n <- nrow(Bikeshare)
p <- length(coef(m))
varPearson <- sum((ePearson^2)) / (n - p)
varPearson # HUGE!
```

### Remedies to overdispersion

- The presence of overdispersion tells us that the distributional assumption we have been making does not hold. Overdispersion is a common problem, and luckily we have a few available remedies, as in alternative distributions, although choosing between them may not always be trival.
  - The **negative binomial** (NB) distribution is a popular choice for modeling data that are overdispersed with respect to the Poisson distribution. The NB can be considered as a member of the exponential family and therefore fitted using standard GLM fitting engines. Just like the Poisson distribution, it is a distribution only appropriate for modeling count data. If
  $$ Y_i \sim NB(\mu_i, \phi), $$
  then $E(Y_i) = \mu_i$ and $Var(Y_i) = \mu_i + \phi \mu_i^2$, with $\phi \ge 0$ the **dispersion parameter**. Since $\phi \ge 0$ the variance of the negative binomial is always larger than that of the Poisson distribution, and in fact is now a quadratic (rather than linear) function of the mean. When $\phi = 0$, the NB reduces to the Poisson distribution.
  - The **quasi-Poisson** model is an alternative choice derived using the quasi-likelihood framework developed by [Wedderburn (1974)](https://www.jstor.org/stable/2334725?seq=1#metadata_info_tab_contents). However, only the first two moments (mean and variance) are specified, and all other moments are left unspecified. In particular if model $Y_i$ using a quasi-Poisson model, then $E(Y_i) = \mu_i$ and $Var(Y_i) = \phi \mu_i$, with $\phi \ge 0$ the **(quasi-)dispersion parameter**. Again, since $\phi \ge 0$ the variance of the quasi-Poisson is always larger than that of the Poisson distribution, however, the dispersion parameter here is on the linear scale, and so the mean-variance relationship is still linear as opposed to quadratic in the NB.
  
 ---
 
 Below, we fit a negative binomial and quasi-Poisson model in `R`.

```{r}
## negative binomial
library(MASS)
mNB <- glm.nb(bikers ~ weathersit + humc + I(humc^2) + I(humc^3) + hr,
         data = Bikeshare)
summary(mNB)
mean(resid(mNB, type = "pearson")^2) # no more overdispersion!

## quasi-Poisson
mQP <- glm(bikers ~ weathersit + humc + I(humc^2) + I(humc^3) + hr,
         data = Bikeshare,
         family="quasipoisson")
# note the dispersion parameter being estimated is equal to our overdispersion diagnostic measure. 
# Indeed, this is the way the dispersion parameter is estimated for the QP!!
summary(mQP) 
```


# A final note

In this lecture, we have introduced GLMs to model data that can be assumed to follow a distribution belonging to the exponential family.
We focussed on estimation, interpretation, statistical inference and some model goodness-of-fit diagnostics. 
We did not consider important topics like model selection, or even whether a GLM is appropriate for your dataset! These are other important topics which, unfortunately, we do not have the bandwidth for to include in this course.
Therefore, a final note through an [XKCD comic](https://xkcd.com/), after finishing this long chapter!

```{r, echo=FALSE, fig.cap=paste("")}
# All defaults
include_graphics("./images_sequencing/xkcd-1725-linear_regression_2x.png")
```


# References

 - [Marioni *et al.* (2008)](https://genome.cshlp.org/content/18/9/1509) describe the distribution of gene expression counts across technical replicates, and in addition discuss lane effects in RNA-seq, as well as a comparison between RNA-seq and array-based platforms.
 - [Wedderburn (1974)](https://www.jstor.org/stable/2334725?seq=1#metadata_info_tab_contents) introduced the (extended) quasi-likelihood framework.
 - The count data chapter of Modern Statistics for Modern Biology by Wolfgang Huber and Susan Holmes handles similar topics also in the context of RNA-seq: https://www.huber.embl.de/msmb/Chap-CountData.html
</div>


</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->
<script>
$(document).ready(function () {
  window.initializeSourceEmbed("sequencing_countData.Rmd");
});
</script>

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3,h4",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
